{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Top2Vec_DataFrame_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nnV6klzpC3ZGgMZdNgicnWsO94-VNEUJ",
      "authorship_tag": "ABX9TyPgEubki6o2QvCXoTX8Hlhe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtype2100/TIL/blob/master/Top2Vec_DataFrame_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top2Vec install"
      ],
      "metadata": {
        "id": "AXeetWqY3uaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install top2vec"
      ],
      "metadata": {
        "id": "1fgmWxPxgaTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8393c84a-e98d-46ef-f4c3-c9357ecf59d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: top2vec in /usr/local/lib/python3.7/dist-packages (1.0.27)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from top2vec) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from top2vec) (1.21.6)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec) (1.5.0)\n",
            "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.7/dist-packages (from top2vec) (0.8.28)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from top2vec) (0.5.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec) (1.3.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec) (6.0.0)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (0.29.28)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->hdbscan>=0.8.27->top2vec) (3.1.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec) (0.5.6)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec) (0.51.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec) (4.64.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (0.34.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->top2vec) (1.15.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install top2vec[sentence_encoders]"
      ],
      "metadata": {
        "id": "drmQDaP0gZB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372461fd-d75c-443a-877c-62335d4a951d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: top2vec[sentence_encoders] in /usr/local/lib/python3.7/dist-packages (1.0.27)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.3.5)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (4.2.0)\n",
            "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.8.28)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.5.0)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (2.8.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec[sentence_encoders]) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec[sentence_encoders]) (6.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.0.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.1.0)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (0.29.28)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->hdbscan>=0.8.27->top2vec[sentence_encoders]) (3.1.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.5.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (4.64.0)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.51.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.34.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->top2vec[sentence_encoders]) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.5.3)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.25.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (4.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.44.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->top2vec[sentence_encoders]) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->top2vec[sentence_encoders]) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.2.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec[sentence_encoders]) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 불러오기"
      ],
      "metadata": {
        "id": "VD4GDbSj36V4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h_FFjQnWaY_d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_excel('/content/drive/MyDrive/NLP/Keyword_extraction/naver_kakao/네이버_증권_산업기업_20170101-20210531.xlsx')\n",
        "df2 = pd.read_excel('/content/drive/MyDrive/NLP/Keyword_extraction/naver_kakao/네이버_증권_산업기업_20210601-20220430.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd2cTp5XdAK8",
        "outputId": "0ffdeb4e-165c-4aa8-ff92-fb0f18e1067d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "Reo5JOiJ4B9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df1, df2]) # 파일 합치기 (종합할 데이터 없으면 각주처리)\n",
        "title_df = df[df['제목'].str.contains('네이버')] # 해당 키워드를 포함한 제목 추출 (불러온 데이터에 따라 키워드 변경)\n",
        "title_df.drop_duplicates(subset=['제목'], inplace=True) # 중복 제거\n",
        "new_df = pd.DataFrame({'일자' : pd.to_datetime(title_df['일자'], format='%Y%m%d'), '제목' : title_df['제목'], 'URL' : title_df['URL']}) # datetime 데이터프레임 생성\n",
        "mask = (new_df['일자'] >= '2021-04-01') & (new_df['일자'] <= '2021-06-30') # 날짜 변경\n",
        "period_df = new_df.loc[mask] # 날짜 인덱싱\n",
        "lis_df = list(period_df['제목']) # 데이터 타입 list로 변경"
      ],
      "metadata": {
        "id": "URKhUbOpdI19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202ec767-0313-4689-b869-9c9a759b3657"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top2Vec"
      ],
      "metadata": {
        "id": "mYy8NXjT4pF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from top2vec import Top2Vec"
      ],
      "metadata": {
        "id": "ujexiW3GgYc7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 훈련"
      ],
      "metadata": {
        "id": "gJ49Iux04uuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Top2Vec(documents=lis_df, speed=\"learn\", workers=8, embedding_model='universal-sentence-encoder')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw_kulh6gs-k",
        "outputId": "f8aedcb3-2693-4ad9-dfa2-03dbf0b1e629"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-10 02:41:34,081 - top2vec - INFO - Pre-processing documents for training\n",
            "INFO:top2vec:Pre-processing documents for training\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "2022-05-10 02:41:34,113 - top2vec - INFO - Downloading universal-sentence-encoder model\n",
            "INFO:top2vec:Downloading universal-sentence-encoder model\n",
            "2022-05-10 02:41:37,404 - top2vec - INFO - Creating joint document/word embedding\n",
            "INFO:top2vec:Creating joint document/word embedding\n",
            "2022-05-10 02:41:37,771 - top2vec - INFO - Creating lower dimension embedding of documents\n",
            "INFO:top2vec:Creating lower dimension embedding of documents\n",
            "2022-05-10 02:41:41,221 - top2vec - INFO - Finding dense areas of documents\n",
            "INFO:top2vec:Finding dense areas of documents\n",
            "2022-05-10 02:41:41,241 - top2vec - INFO - Finding topics\n",
            "INFO:top2vec:Finding topics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 토픽 수 확인"
      ],
      "metadata": {
        "id": "X_ok6k4s4xVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_num_topics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlgsDYWLg0o6",
        "outputId": "98471b60-69e0-4728-9df0-2ce1d9bcb466"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 토픽 확인, 검색 토픽 설정, Topic num 설정"
      ],
      "metadata": {
        "id": "eJAlQPkB4z3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_sizes, topic_nums = model.get_topic_sizes()\n",
        "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"네이버\"], num_topics=2) # num_topics는 'model.get_num_topics()'에 나온 수와 동일하게 설정. keywords에 확인할 키워드 설정."
      ],
      "metadata": {
        "id": "zIgqs-HZg2dL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_words # 토픽 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL-CtTKahAj7",
        "outputId": "486fc8e4-ef0a-4292-cdc5-daa601779665"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['네이버', '이베이코리아', '신세계', '시총', '카카오'], dtype='<U6'),\n",
              " array(['네이버', '이베이코리아', '카카오', '신세계', '시총'], dtype='<U6')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 유사도 높은 뉴스 출력 및 Score 확인"
      ],
      "metadata": {
        "id": "yrnx-X9u5hZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=1, num_docs=16) # 필요한 만큼 topic_num 변경, num_docs 변경\n",
        "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
        "    print(f\"Document: {doc_id}, Score: {score}\")\n",
        "    print(\"-----------\")\n",
        "    print(doc)\n",
        "    print(\"-----------\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVaOozghhGmC",
        "outputId": "5080d4c9-6dff-47a0-c5d2-482a1fbac846"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document: 495, Score: 0.8380758762359619\n",
            "-----------\n",
            "`신세계 네이버 vs 롯데` 이베이 인수 2파전\n",
            "-----------\n",
            "\n",
            "Document: 96, Score: 0.8342318534851074\n",
            "-----------\n",
            "카카오 vs 네이버, 판커지는 ‘선물하기’ 시장[언박싱]\n",
            "-----------\n",
            "\n",
            "Document: 493, Score: 0.8323456048965454\n",
            "-----------\n",
            "빅테크 분석서 '네이버 vs 카카오' 인기\n",
            "-----------\n",
            "\n",
            "Document: 259, Score: 0.8315381407737732\n",
            "-----------\n",
            "요동치는 e커머스 시장 신세계 VS 쿠팡 VS 네이버\n",
            "-----------\n",
            "\n",
            "Document: 242, Score: 0.8147686719894409\n",
            "-----------\n",
            "이베이 인수 이마트, 네이버 쿠팡과 新3강 게임 체인저 vs 승자의 저주\n",
            "-----------\n",
            "\n",
            "Document: 391, Score: 0.8124184012413025\n",
            "-----------\n",
            "e커머스 업계 3강 구도 재편? 신세계 네이버 vs 쿠팡\n",
            "-----------\n",
            "\n",
            "Document: 73, Score: 0.8058498501777649\n",
            "-----------\n",
            "네이버 vs 카카오, 글로벌 콘텐츠 전쟁 서막 올랐다\n",
            "-----------\n",
            "\n",
            "Document: 457, Score: 0.805296778678894\n",
            "-----------\n",
            "카카오 vs 네이버 시총 3위 놓고 진검승부 펼친다\n",
            "-----------\n",
            "\n",
            "Document: 264, Score: 0.7952497005462646\n",
            "-----------\n",
            "[투자뉴스7] '국민주' 카카오 VS '큰 손 사랑' 네이버 \"자식에게 물려줄거면 \"\n",
            "-----------\n",
            "\n",
            "Document: 21, Score: 0.7858288884162903\n",
            "-----------\n",
            "‘네이버 vs 카카오’ 몸집전쟁 불 붙었다\n",
            "-----------\n",
            "\n",
            "Document: 494, Score: 0.7812486886978149\n",
            "-----------\n",
            "롯데 vs 신세계 네이버연합 이베이코리아 인수 '2파전'\n",
            "-----------\n",
            "\n",
            "Document: 162, Score: 0.780164361000061\n",
            "-----------\n",
            "네이버 VS 쿠팡, 디지털 공룡들의 불꽃 튀는 '쇼핑 전쟁' [박동휘의 컨슈머 리포트]\n",
            "-----------\n",
            "\n",
            "Document: 400, Score: 0.763900637626648\n",
            "-----------\n",
            "네이버 vs 카카오, 불 붙은 시총경쟁...플랫폼 지각변동 예고 [홍길용의 화식열전]\n",
            "-----------\n",
            "\n",
            "Document: 228, Score: 0.7458733320236206\n",
            "-----------\n",
            "Z홀딩스 vs 카도카와 네이버 카카오, 일본서도 서학개미 주주열전 [株포트라이트]\n",
            "-----------\n",
            "\n",
            "Document: 15, Score: 0.7348618507385254\n",
            "-----------\n",
            "[BOOK] 네이버 vs 카카오 | 자체분열 네이버 vs 인수합병 카카오\n",
            "-----------\n",
            "\n",
            "Document: 415, Score: 0.6777425408363342\n",
            "-----------\n",
            "[ET] 불붙은 넘버3 경쟁 네이버 vs 카카오, 뭘 담을까?\n",
            "-----------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top2Vec으로 추출한 문서를 데이터프레임으로 만들기"
      ],
      "metadata": {
        "id": "naMZSbbU55rY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_df = pd.DataFrame({'일자' : document_ids, '제목' : documents, 'URL' : document_scores}) # Top2Vec을 데이터프레임으로 만들기\n",
        "sum_df = pd.concat([doc_df, period_df]) # Top2Vec에서 추출한 데이터와 날짜 인덱싱한 데이터와 합치기\n",
        "dupl_df = sum_df[sum_df['제목'].duplicated()] # Top2Vec에서 추출한 데이터와 날짜 인덱싱한 데이터에서 중복값 변수 설정\n",
        "date_df = pd.DataFrame({'일자' : pd.to_datetime(dupl_df['일자'], format='%Y%m%d'), '제목' : dupl_df['제목'], 'URL' : dupl_df['URL']}) # 중복값 설정한 데이터에 datetime 순서로 데이터프레임 생성\n",
        "sort_df = date_df.sort_values(by=['일자']) # 데이터프레임을 일자별로 정렬"
      ],
      "metadata": {
        "id": "yRC9TBkK0Sha"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sort_df.info() # 데이터 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuCkNtce2Rtk",
        "outputId": "a0d8ae1c-a3ea-4026-dee7-b0e246687cce"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 16 entries, 1076 to 5367\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   일자      16 non-null     datetime64[ns]\n",
            " 1   제목      16 non-null     object        \n",
            " 2   URL     16 non-null     object        \n",
            "dtypes: datetime64[ns](1), object(2)\n",
            "memory usage: 512.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추출한 데이터 엑셀로 저장"
      ],
      "metadata": {
        "id": "Jb4cszfV6Irm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sort_df.to_excel('네이버_증권_산업기업_20210401_20210631.xlsx') # 엑셀로 저장"
      ],
      "metadata": {
        "id": "kxvPXiLJYhjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9Vq_-6RVoxO4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}