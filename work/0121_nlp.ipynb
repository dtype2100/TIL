{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb5bef7-5c3e-46d7-93fd-a0f767043cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e29338c-cefb-4f6a-8f64-e39419e8d7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"words\")\n",
    "nltk.download(\"maxent_ne_chunker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "756cf605-5be2-4a14-92de-8213ccb85382",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Good muffins cost $3.88\\nin New York. Please buy me\\ntwo of them.\\n\\nThanks.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12de814d-16c6-49e1-bf08-22a199bac2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f53976-9ef5-46c0-93e1-0756049ec52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_chunk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9780dcf-decc-48af-90ca-f1fa6c4c731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8cdf7d9-b5c8-4ac6-8812-9d4db3bbd4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'muffins',\n",
       " 'cost',\n",
       " '$',\n",
       " '3.88',\n",
       " 'in',\n",
       " 'New',\n",
       " 'York',\n",
       " '.',\n",
       " 'Please',\n",
       " 'buy',\n",
       " 'me',\n",
       " 'two',\n",
       " 'of',\n",
       " 'them',\n",
       " '.',\n",
       " 'Thanks',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae92383-adda-42c5-9d75-9ea05442d3ca",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Good', 'JJ'),\n",
       " ('muffins', 'NNS'),\n",
       " ('cost', 'VBP'),\n",
       " ('$', '$'),\n",
       " ('3.88', 'CD'),\n",
       " ('in', 'IN'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Please', 'NNP'),\n",
       " ('buy', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('two', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('Thanks', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "pos_tagged = pos_tag(word_tokens)\n",
    "pos_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9b55b5-8373-48d4-b39b-abcbd1f15427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,760.0,168.0\" width=\"760px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"6.31579%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Good</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.15789%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"9.47368%\" x=\"6.31579%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">muffins</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.0526%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.31579%\" x=\"15.7895%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cost</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.9474%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"22.1053%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">$</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"23.6842%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.31579%\" x=\"25.2632%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">3.88</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.4211%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.21053%\" x=\"31.5789%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"33.6842%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"11.5789%\" x=\"35.7895%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">GPE</text></svg><svg width=\"45.4545%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">New</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"54.5455%\" x=\"45.4545%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">York</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.7273%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"41.5789%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"47.3684%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.9474%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"8.42105%\" x=\"50.5263%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Please</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.7368%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.26316%\" x=\"58.9474%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">buy</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.5789%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.26316%\" x=\"64.2105%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">me</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.8421%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.26316%\" x=\"69.4737%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">two</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.1053%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.21053%\" x=\"74.7368%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"76.8421%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.31579%\" x=\"78.9474%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">them</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.1053%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"85.2632%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"86.8421%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"8.42105%\" x=\"88.4211%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Thanks</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.6316%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"96.8421%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.4211%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('GPE', [('Good', 'JJ')]), ('muffins', 'NNS'), ('cost', 'VBP'), ('$', '$'), ('3.88', 'CD'), ('in', 'IN'), Tree('GPE', [('New', 'NNP'), ('York', 'NNP')]), ('.', '.'), ('Please', 'NNP'), ('buy', 'VB'), ('me', 'PRP'), ('two', 'CD'), ('of', 'IN'), ('them', 'PRP'), ('.', '.'), ('Thanks', 'NNS'), ('.', '.')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_tokens = ne_chunk(pos_tagged)\n",
    "ne_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f843bb4e-b8ea-444d-ba25-e8209e8b5c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Good/JJ)\n",
      "  muffins/NNS\n",
      "  cost/VBP\n",
      "  $/$\n",
      "  3.88/CD\n",
      "  in/IN\n",
      "  (GPE New/NNP York/NNP)\n",
      "  ./.\n",
      "  Please/NNP\n",
      "  buy/VB\n",
      "  me/PRP\n",
      "  two/CD\n",
      "  of/IN\n",
      "  them/PRP\n",
      "  ./.\n",
      "  Thanks/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(ne_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38de3926-b92c-428d-9a3a-164a1651e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "956a86ae-8692-4385-90a3-94f3de61f108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.88, New York, two)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db4dbc2d-8241-47a7-9379-f72c0d0327c5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good ADJ\n",
      "muffins NOUN\n",
      "cost VERB\n",
      "$ SYM\n",
      "3.88 NUM\n",
      "\n",
      " SPACE\n",
      "in ADP\n",
      "New PROPN\n",
      "York PROPN\n",
      ". PUNCT\n",
      "Please INTJ\n",
      "buy VERB\n",
      "me PRON\n",
      "\n",
      " SPACE\n",
      "two NUM\n",
      "of ADP\n",
      "them PRON\n",
      ". PUNCT\n",
      "\n",
      "\n",
      " SPACE\n",
      "Thanks X\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2303c19e-355e-4617-859a-e8b41944937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running -> run\n",
      "beautiful -> beauti\n",
      "believes -> believ\n",
      "using -> use\n",
      "conversation -> convers\n",
      "organization -> organ\n",
      "studies -> studi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "print(\"running ->\", ps.stem(\"running\"))\n",
    "print(\"beautiful ->\", ps.stem(\"beautiful\"))\n",
    "print(\"believes ->\", ps.stem(\"believes\"))\n",
    "print(\"using ->\", ps.stem(\"using\"))\n",
    "print(\"conversation ->\", ps.stem(\"conversation\"))\n",
    "print(\"organization ->\", ps.stem(\"organization\"))\n",
    "print(\"studies ->\", ps.stem(\"studies\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eb8f4eb-87f8-403e-8f00-d4ec08fa8629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af1faab4-4a56-454c-82cd-cc96223d4b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running -> running\n",
      "beautiful -> beautiful\n",
      "believes -> belief\n",
      "using -> using\n",
      "conversation -> conversation\n",
      "organization -> organization\n",
      "studies -> study\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wn = WordNetLemmatizer()\n",
    "\n",
    "print(\"running ->\", wn.lemmatize(\"running\"))\n",
    "print(\"beautiful ->\", wn.lemmatize(\"beautiful\"))\n",
    "print(\"believes ->\", wn.lemmatize(\"believes\"))\n",
    "print(\"using ->\", wn.lemmatize(\"using\"))\n",
    "print(\"conversation ->\", wn.lemmatize(\"conversation\"))\n",
    "print(\"organization ->\", wn.lemmatize(\"organization\"))\n",
    "print(\"studies ->\", wn.lemmatize(\"studies\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f33369a-2fa1-4af4-8c15-998657bf8e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc85d431-af4c-4cdd-a29b-79837c5bf485",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24b2a8e8-598b-46ea-a876-c77455b0f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_pos = [\"IN\", \"CC\", \"UH\", \"TO\", \"MD\", \"DT\", \"VBZ\", \"VBP\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4405e371-b57f-453b-9833-44a8a0be9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/?sh=241229d11f25\"\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "eng_news = soup.select(\".article-body p\")\n",
    "article  = [p.text for p in eng_news[1:10]]\n",
    "text = \"\\n\".join(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e43bc78-e2ea-4540-adce-62f5644da48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens = word_tokenize(text)\n",
    "pos_tagged = pos_tag(word_tokens)\n",
    "len(pos_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d60bb5a-3547-4356-a639-4dafc987f760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "for word, pos in pos_tagged:\n",
    "    if word.lower() not in stopwords.words('english') and pos not in stop_pos:\n",
    "        words.append(word)\n",
    "        \n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65906b9e-e4d1-4b42-8d40-77c2521880cf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['present-day',\n",
       " 'darling',\n",
       " 'tech',\n",
       " 'world',\n",
       " '.',\n",
       " 'current',\n",
       " 'renaissance',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " '(',\n",
       " 'AI',\n",
       " ')',\n",
       " 'sister',\n",
       " 'discipline',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " '(',\n",
       " 'ML',\n",
       " ')',\n",
       " 'led',\n",
       " 'firm',\n",
       " 'worth',\n",
       " 'salt',\n",
       " 'engineer',\n",
       " 'form',\n",
       " 'AI',\n",
       " 'platform',\n",
       " ',',\n",
       " 'toolsets',\n",
       " 'software',\n",
       " 'applications',\n",
       " '.',\n",
       " 'IBM',\n",
       " 'CEO',\n",
       " 'Ginni',\n",
       " 'Rometty',\n",
       " 'already',\n",
       " 'proclaimed',\n",
       " 'AI',\n",
       " 'change',\n",
       " '100',\n",
       " 'percent',\n",
       " 'jobs',\n",
       " 'next',\n",
       " 'decade',\n",
       " '.',\n",
       " ',',\n",
       " 'mean',\n",
       " 'everybody',\n",
       " \"'s\",\n",
       " 'job',\n",
       " 'mine',\n",
       " 'onward',\n",
       " 'role',\n",
       " 'grain',\n",
       " 'farmers',\n",
       " 'Egypt',\n",
       " ',',\n",
       " 'pastry',\n",
       " 'chefs',\n",
       " 'Paris',\n",
       " 'dog',\n",
       " 'walkers',\n",
       " 'Oregon',\n",
       " 'i.e',\n",
       " '.',\n",
       " 'job',\n",
       " '.',\n",
       " 'able',\n",
       " 'help',\n",
       " 'direct',\n",
       " 'workers',\n",
       " 'actions',\n",
       " 'behavior',\n",
       " 'new',\n",
       " 'degree',\n",
       " 'intelligence',\n",
       " 'predictive',\n",
       " 'analytics',\n",
       " ',',\n",
       " 'stemming',\n",
       " 'AI',\n",
       " 'increasingly',\n",
       " 'upon',\n",
       " '.',\n",
       " 'right',\n",
       " '?',\n",
       " 'AI',\n",
       " 'used',\n",
       " 'fanciful',\n",
       " 'notion',\n",
       " 'mostly',\n",
       " 'confined',\n",
       " 'science',\n",
       " 'fiction',\n",
       " ',',\n",
       " 'go',\n",
       " 'right',\n",
       " '?',\n",
       " 'recent',\n",
       " 'years',\n",
       " 'big',\n",
       " 'changes',\n",
       " 'technology',\n",
       " '.',\n",
       " 'Aside',\n",
       " 'proliferation',\n",
       " 'mobile',\n",
       " 'devices',\n",
       " 'impacted',\n",
       " 'us',\n",
       " ',',\n",
       " 'memory',\n",
       " 'become',\n",
       " 'lot',\n",
       " 'cheaper',\n",
       " ',',\n",
       " 'data',\n",
       " 'storage',\n",
       " 'become',\n",
       " 'lot',\n",
       " 'easier',\n",
       " '(',\n",
       " 'cloud',\n",
       " ',',\n",
       " 'elsewhere',\n",
       " ')',\n",
       " 'computer',\n",
       " 'processing',\n",
       " 'speeds',\n",
       " 'continued',\n",
       " 'outstrip',\n",
       " 'previous',\n",
       " 'records',\n",
       " '.',\n",
       " 'power',\n",
       " 'quantum',\n",
       " 'computing',\n",
       " 'corner',\n",
       " ',',\n",
       " 'AI',\n",
       " 'renaissance',\n",
       " 'simply',\n",
       " 'result',\n",
       " 'coming',\n",
       " 'together',\n",
       " '‘',\n",
       " 'tech',\n",
       " 'ingredient',\n",
       " '’',\n",
       " 'forces',\n",
       " '?',\n",
       " '“',\n",
       " \"n't\",\n",
       " 'massive',\n",
       " 'compute',\n",
       " 'power',\n",
       " '.',\n",
       " 'important',\n",
       " 'algorithmic',\n",
       " 'changes',\n",
       " 'developed',\n",
       " '.',\n",
       " ',',\n",
       " 'much',\n",
       " 'easier',\n",
       " 'gain',\n",
       " 'access',\n",
       " 'data',\n",
       " 'Internet-connected',\n",
       " 'world',\n",
       " ',',\n",
       " '”',\n",
       " 'said',\n",
       " 'Ted',\n",
       " 'Dunning',\n",
       " ',',\n",
       " 'CTO',\n",
       " 'data',\n",
       " 'platform',\n",
       " ',',\n",
       " 'AI',\n",
       " 'analytics',\n",
       " 'company',\n",
       " 'MapR',\n",
       " '.',\n",
       " '“',\n",
       " 'three',\n",
       " 'aspects',\n",
       " '(',\n",
       " 'compute',\n",
       " ',',\n",
       " 'algorithms',\n",
       " ',',\n",
       " 'data',\n",
       " ')',\n",
       " 'make',\n",
       " 'todays',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'possible',\n",
       " '.',\n",
       " 'Also',\n",
       " 'quite',\n",
       " 'frankly',\n",
       " ',',\n",
       " 'lot',\n",
       " 'applications',\n",
       " 'data',\n",
       " 'availability',\n",
       " '...',\n",
       " 'implemented',\n",
       " '25',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'pretty',\n",
       " 'easily',\n",
       " 'data',\n",
       " 'available',\n",
       " 'output',\n",
       " 'model',\n",
       " 'integrated',\n",
       " 'back',\n",
       " 'business',\n",
       " 'flow.',\n",
       " '”',\n",
       " ',',\n",
       " 'many',\n",
       " 'ways',\n",
       " ',',\n",
       " 'Dunning',\n",
       " 'really',\n",
       " 'modern',\n",
       " 'era',\n",
       " 'web',\n",
       " 'key',\n",
       " 'facilitator',\n",
       " 'new',\n",
       " 'age',\n",
       " 'AI',\n",
       " '.',\n",
       " 'Information',\n",
       " 'become',\n",
       " 'ubiquitous',\n",
       " ';',\n",
       " 'also',\n",
       " 'become',\n",
       " 'easier',\n",
       " 'access',\n",
       " 'accurately',\n",
       " 'classified',\n",
       " 'structured',\n",
       " ',',\n",
       " 'semi-structured',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " 'rawest',\n",
       " 'form',\n",
       " '.',\n",
       " 'Tuning',\n",
       " 'AI',\n",
       " 'towards',\n",
       " 'life']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de98aa65-7eb9-4c75-bd8c-a6fb1f4335cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbc65ecb-503f-4b95-bbcb-80f6307f50bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19),\n",
       " ('.', 14),\n",
       " ('AI', 9),\n",
       " ('data', 7),\n",
       " ('(', 4),\n",
       " (')', 4),\n",
       " ('become', 4),\n",
       " ('?', 3),\n",
       " ('lot', 3),\n",
       " ('easier', 3),\n",
       " ('tech', 2),\n",
       " ('world', 2),\n",
       " ('renaissance', 2),\n",
       " ('form', 2),\n",
       " ('platform', 2),\n",
       " ('applications', 2),\n",
       " ('job', 2),\n",
       " ('new', 2),\n",
       " ('analytics', 2),\n",
       " ('right', 2),\n",
       " ('years', 2),\n",
       " ('changes', 2),\n",
       " ('power', 2),\n",
       " ('“', 2),\n",
       " ('compute', 2),\n",
       " ('access', 2),\n",
       " ('”', 2),\n",
       " ('Dunning', 2),\n",
       " ('present-day', 1),\n",
       " ('darling', 1),\n",
       " ('current', 1),\n",
       " ('Artificial', 1),\n",
       " ('Intelligence', 1),\n",
       " ('sister', 1),\n",
       " ('discipline', 1),\n",
       " ('Machine', 1),\n",
       " ('Learning', 1),\n",
       " ('ML', 1),\n",
       " ('led', 1),\n",
       " ('firm', 1),\n",
       " ('worth', 1),\n",
       " ('salt', 1),\n",
       " ('engineer', 1),\n",
       " ('toolsets', 1),\n",
       " ('software', 1),\n",
       " ('IBM', 1),\n",
       " ('CEO', 1),\n",
       " ('Ginni', 1),\n",
       " ('Rometty', 1),\n",
       " ('already', 1),\n",
       " ('proclaimed', 1),\n",
       " ('change', 1),\n",
       " ('100', 1),\n",
       " ('percent', 1),\n",
       " ('jobs', 1),\n",
       " ('next', 1),\n",
       " ('decade', 1),\n",
       " ('mean', 1),\n",
       " ('everybody', 1),\n",
       " (\"'s\", 1),\n",
       " ('mine', 1),\n",
       " ('onward', 1),\n",
       " ('role', 1),\n",
       " ('grain', 1),\n",
       " ('farmers', 1),\n",
       " ('Egypt', 1),\n",
       " ('pastry', 1),\n",
       " ('chefs', 1),\n",
       " ('Paris', 1),\n",
       " ('dog', 1),\n",
       " ('walkers', 1),\n",
       " ('Oregon', 1),\n",
       " ('i.e', 1),\n",
       " ('able', 1),\n",
       " ('help', 1),\n",
       " ('direct', 1),\n",
       " ('workers', 1),\n",
       " ('actions', 1),\n",
       " ('behavior', 1),\n",
       " ('degree', 1),\n",
       " ('intelligence', 1),\n",
       " ('predictive', 1),\n",
       " ('stemming', 1),\n",
       " ('increasingly', 1),\n",
       " ('upon', 1),\n",
       " ('used', 1),\n",
       " ('fanciful', 1),\n",
       " ('notion', 1),\n",
       " ('mostly', 1),\n",
       " ('confined', 1),\n",
       " ('science', 1),\n",
       " ('fiction', 1),\n",
       " ('go', 1),\n",
       " ('recent', 1),\n",
       " ('big', 1),\n",
       " ('technology', 1),\n",
       " ('Aside', 1),\n",
       " ('proliferation', 1),\n",
       " ('mobile', 1),\n",
       " ('devices', 1),\n",
       " ('impacted', 1),\n",
       " ('us', 1),\n",
       " ('memory', 1),\n",
       " ('cheaper', 1),\n",
       " ('storage', 1),\n",
       " ('cloud', 1),\n",
       " ('elsewhere', 1),\n",
       " ('computer', 1),\n",
       " ('processing', 1),\n",
       " ('speeds', 1),\n",
       " ('continued', 1),\n",
       " ('outstrip', 1),\n",
       " ('previous', 1),\n",
       " ('records', 1),\n",
       " ('quantum', 1),\n",
       " ('computing', 1),\n",
       " ('corner', 1),\n",
       " ('simply', 1),\n",
       " ('result', 1),\n",
       " ('coming', 1),\n",
       " ('together', 1),\n",
       " ('‘', 1),\n",
       " ('ingredient', 1),\n",
       " ('’', 1),\n",
       " ('forces', 1),\n",
       " (\"n't\", 1),\n",
       " ('massive', 1),\n",
       " ('important', 1),\n",
       " ('algorithmic', 1),\n",
       " ('developed', 1),\n",
       " ('much', 1),\n",
       " ('gain', 1),\n",
       " ('Internet-connected', 1),\n",
       " ('said', 1),\n",
       " ('Ted', 1),\n",
       " ('CTO', 1),\n",
       " ('company', 1),\n",
       " ('MapR', 1),\n",
       " ('three', 1),\n",
       " ('aspects', 1),\n",
       " ('algorithms', 1),\n",
       " ('make', 1),\n",
       " ('todays', 1),\n",
       " ('machine', 1),\n",
       " ('learning', 1),\n",
       " ('possible', 1),\n",
       " ('Also', 1),\n",
       " ('quite', 1),\n",
       " ('frankly', 1),\n",
       " ('availability', 1),\n",
       " ('...', 1),\n",
       " ('implemented', 1),\n",
       " ('25', 1),\n",
       " ('ago', 1),\n",
       " ('pretty', 1),\n",
       " ('easily', 1),\n",
       " ('available', 1),\n",
       " ('output', 1),\n",
       " ('model', 1),\n",
       " ('integrated', 1),\n",
       " ('back', 1),\n",
       " ('business', 1),\n",
       " ('flow.', 1),\n",
       " ('many', 1),\n",
       " ('ways', 1),\n",
       " ('really', 1),\n",
       " ('modern', 1),\n",
       " ('era', 1),\n",
       " ('web', 1),\n",
       " ('key', 1),\n",
       " ('facilitator', 1),\n",
       " ('age', 1),\n",
       " ('Information', 1),\n",
       " ('ubiquitous', 1),\n",
       " (';', 1),\n",
       " ('also', 1),\n",
       " ('accurately', 1),\n",
       " ('classified', 1),\n",
       " ('structured', 1),\n",
       " ('semi-structured', 1),\n",
       " ('unstructured', 1),\n",
       " ('rawest', 1),\n",
       " ('Tuning', 1),\n",
       " ('towards', 1),\n",
       " ('life', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b7b65a5-21e4-4ff0-947e-f9db27266dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = []\n",
    "for word in words:\n",
    "    stemmed_words.append(ps.stem(word))\n",
    "    \n",
    "lemmed_words = []\n",
    "for word in stemmed_words:\n",
    "    lemmed_words.append(wn.lemmatize(word))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a2ba074-3b5d-466b-8916-394026fd499d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19),\n",
       " ('.', 14),\n",
       " ('ai', 9),\n",
       " ('data', 7),\n",
       " ('(', 4),\n",
       " (')', 4),\n",
       " ('becom', 4),\n",
       " ('comput', 4),\n",
       " ('chang', 3),\n",
       " ('job', 3),\n",
       " ('?', 3),\n",
       " ('lot', 3),\n",
       " ('easier', 3),\n",
       " ('tech', 2),\n",
       " ('world', 2),\n",
       " ('renaiss', 2),\n",
       " ('intellig', 2),\n",
       " ('machin', 2),\n",
       " ('learn', 2),\n",
       " ('form', 2),\n",
       " ('platform', 2),\n",
       " ('applic', 2),\n",
       " ('new', 2),\n",
       " ('analyt', 2),\n",
       " ('right', 2),\n",
       " ('year', 2),\n",
       " ('power', 2),\n",
       " ('“', 2),\n",
       " ('algorithm', 2),\n",
       " ('access', 2),\n",
       " ('”', 2),\n",
       " ('dun', 2),\n",
       " ('also', 2),\n",
       " ('avail', 2),\n",
       " ('present-day', 1),\n",
       " ('darl', 1),\n",
       " ('current', 1),\n",
       " ('artifici', 1),\n",
       " ('sister', 1),\n",
       " ('disciplin', 1),\n",
       " ('ml', 1),\n",
       " ('led', 1),\n",
       " ('firm', 1),\n",
       " ('worth', 1),\n",
       " ('salt', 1),\n",
       " ('engin', 1),\n",
       " ('toolset', 1),\n",
       " ('softwar', 1),\n",
       " ('ibm', 1),\n",
       " ('ceo', 1),\n",
       " ('ginni', 1),\n",
       " ('rometti', 1),\n",
       " ('alreadi', 1),\n",
       " ('proclaim', 1),\n",
       " ('100', 1),\n",
       " ('percent', 1),\n",
       " ('next', 1),\n",
       " ('decad', 1),\n",
       " ('mean', 1),\n",
       " ('everybodi', 1),\n",
       " (\"'s\", 1),\n",
       " ('mine', 1),\n",
       " ('onward', 1),\n",
       " ('role', 1),\n",
       " ('grain', 1),\n",
       " ('farmer', 1),\n",
       " ('egypt', 1),\n",
       " ('pastri', 1),\n",
       " ('chef', 1),\n",
       " ('pari', 1),\n",
       " ('dog', 1),\n",
       " ('walker', 1),\n",
       " ('oregon', 1),\n",
       " ('i.e', 1),\n",
       " ('abl', 1),\n",
       " ('help', 1),\n",
       " ('direct', 1),\n",
       " ('worker', 1),\n",
       " ('action', 1),\n",
       " ('behavior', 1),\n",
       " ('degre', 1),\n",
       " ('predict', 1),\n",
       " ('stem', 1),\n",
       " ('increasingli', 1),\n",
       " ('upon', 1),\n",
       " ('use', 1),\n",
       " ('fanci', 1),\n",
       " ('notion', 1),\n",
       " ('mostli', 1),\n",
       " ('confin', 1),\n",
       " ('scienc', 1),\n",
       " ('fiction', 1),\n",
       " ('go', 1),\n",
       " ('recent', 1),\n",
       " ('big', 1),\n",
       " ('technolog', 1),\n",
       " ('asid', 1),\n",
       " ('prolifer', 1),\n",
       " ('mobil', 1),\n",
       " ('devic', 1),\n",
       " ('impact', 1),\n",
       " ('u', 1),\n",
       " ('memori', 1),\n",
       " ('cheaper', 1),\n",
       " ('storag', 1),\n",
       " ('cloud', 1),\n",
       " ('elsewher', 1),\n",
       " ('process', 1),\n",
       " ('speed', 1),\n",
       " ('continu', 1),\n",
       " ('outstrip', 1),\n",
       " ('previou', 1),\n",
       " ('record', 1),\n",
       " ('quantum', 1),\n",
       " ('corner', 1),\n",
       " ('simpli', 1),\n",
       " ('result', 1),\n",
       " ('come', 1),\n",
       " ('togeth', 1),\n",
       " ('‘', 1),\n",
       " ('ingredi', 1),\n",
       " ('’', 1),\n",
       " ('forc', 1),\n",
       " (\"n't\", 1),\n",
       " ('massiv', 1),\n",
       " ('import', 1),\n",
       " ('develop', 1),\n",
       " ('much', 1),\n",
       " ('gain', 1),\n",
       " ('internet-connect', 1),\n",
       " ('said', 1),\n",
       " ('ted', 1),\n",
       " ('cto', 1),\n",
       " ('compani', 1),\n",
       " ('mapr', 1),\n",
       " ('three', 1),\n",
       " ('aspect', 1),\n",
       " ('make', 1),\n",
       " ('today', 1),\n",
       " ('possibl', 1),\n",
       " ('quit', 1),\n",
       " ('frankli', 1),\n",
       " ('...', 1),\n",
       " ('implement', 1),\n",
       " ('25', 1),\n",
       " ('ago', 1),\n",
       " ('pretti', 1),\n",
       " ('easili', 1),\n",
       " ('output', 1),\n",
       " ('model', 1),\n",
       " ('integr', 1),\n",
       " ('back', 1),\n",
       " ('busi', 1),\n",
       " ('flow.', 1),\n",
       " ('mani', 1),\n",
       " ('way', 1),\n",
       " ('realli', 1),\n",
       " ('modern', 1),\n",
       " ('era', 1),\n",
       " ('web', 1),\n",
       " ('key', 1),\n",
       " ('facilit', 1),\n",
       " ('age', 1),\n",
       " ('inform', 1),\n",
       " ('ubiquit', 1),\n",
       " (';', 1),\n",
       " ('accur', 1),\n",
       " ('classifi', 1),\n",
       " ('structur', 1),\n",
       " ('semi-structur', 1),\n",
       " ('unstructur', 1),\n",
       " ('rawest', 1),\n",
       " ('tune', 1),\n",
       " ('toward', 1),\n",
       " ('life', 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(lemmed_words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637c222-0346-4bfe-8080-7583f91af28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
