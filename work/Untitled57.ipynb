{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ffcf355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import  numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aad23f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"words\")\n",
    "nltk.download(\"maxent_ne_chunker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3db2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Good muffins cost $3.88\\nin New York. Please buy me\\ntwo of them.\\n\\nThanks.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d5098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41579ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'muffins',\n",
       " 'cost',\n",
       " '$',\n",
       " '3.88',\n",
       " 'in',\n",
       " 'New',\n",
       " 'York',\n",
       " '.',\n",
       " 'Please',\n",
       " 'buy',\n",
       " 'me',\n",
       " 'two',\n",
       " 'of',\n",
       " 'them',\n",
       " '.',\n",
       " 'Thanks',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokens = word_tokenize(text)\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b592829f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Good', 'JJ'),\n",
       " ('muffins', 'NNS'),\n",
       " ('cost', 'VBP'),\n",
       " ('$', '$'),\n",
       " ('3.88', 'CD'),\n",
       " ('in', 'IN'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Please', 'NNP'),\n",
       " ('buy', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('two', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('Thanks', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "pos_tagged = (pos_tag(word_tokens))\n",
    "pos_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557b9703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: svgling in c:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: svgwrite in c:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages (from svgling) (1.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install svgling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efeb67b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,760.0,168.0\" width=\"760px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"6.31579%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Good</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.15789%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"9.47368%\" x=\"6.31579%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">muffins</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.0526%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.31579%\" x=\"15.7895%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cost</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.9474%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"22.1053%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">$</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"23.6842%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.31579%\" x=\"25.2632%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">3.88</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.4211%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.21053%\" x=\"31.5789%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"33.6842%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"11.5789%\" x=\"35.7895%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">GPE</text></svg><svg width=\"45.4545%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">New</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"54.5455%\" x=\"45.4545%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">York</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.7273%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"41.5789%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"47.3684%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.9474%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"8.42105%\" x=\"50.5263%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Please</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.7368%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.26316%\" x=\"58.9474%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">buy</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.5789%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.26316%\" x=\"64.2105%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">me</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.8421%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.26316%\" x=\"69.4737%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">two</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.1053%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.21053%\" x=\"74.7368%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"76.8421%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.31579%\" x=\"78.9474%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">them</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.1053%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"85.2632%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"86.8421%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"8.42105%\" x=\"88.4211%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Thanks</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.6316%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"96.8421%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.4211%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('GPE', [('Good', 'JJ')]), ('muffins', 'NNS'), ('cost', 'VBP'), ('$', '$'), ('3.88', 'CD'), ('in', 'IN'), Tree('GPE', [('New', 'NNP'), ('York', 'NNP')]), ('.', '.'), ('Please', 'NNP'), ('buy', 'VB'), ('me', 'PRP'), ('two', 'CD'), ('of', 'IN'), ('them', 'PRP'), ('.', '.'), ('Thanks', 'NNS'), ('.', '.')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_tokens = ne_chunk(pos_tagged)\n",
    "ne_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8794fd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Good/JJ)\n",
      "  muffins/NNS\n",
      "  cost/VBP\n",
      "  $/$\n",
      "  3.88/CD\n",
      "  in/IN\n",
      "  (GPE New/NNP York/NNP)\n",
      "  ./.\n",
      "  Please/NNP\n",
      "  buy/VB\n",
      "  me/PRP\n",
      "  two/CD\n",
      "  of/IN\n",
      "  them/PRP\n",
      "  ./.\n",
      "  Thanks/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(ne_tokens) #name entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573e5e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e5e5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.88, New York, two)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents #데이터 확인을 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "192ceaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good ADJ\n",
      "muffins NOUN\n",
      "cost VERB\n",
      "$ SYM\n",
      "3.88 NUM\n",
      "\n",
      " SPACE\n",
      "in ADP\n",
      "New PROPN\n",
      "York PROPN\n",
      ". PUNCT\n",
      "Please INTJ\n",
      "buy VERB\n",
      "me PRON\n",
      "\n",
      " SPACE\n",
      "two NUM\n",
      "of ADP\n",
      "them PRON\n",
      ". PUNCT\n",
      "\n",
      "\n",
      " SPACE\n",
      "Thanks X\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bc37ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running -> run\n",
      "beautiful -> beauti\n",
      "believes -> believ\n",
      "using -> use\n",
      "conversation -> convers\n",
      "organization -> organ\n",
      "studies -> studi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "print(\"running ->\", ps.stem(\"running\"))\n",
    "print(\"beautiful ->\", ps.stem(\"beautiful\"))\n",
    "print(\"believes ->\", ps.stem(\"believes\"))\n",
    "print(\"using ->\", ps.stem(\"using\"))\n",
    "print(\"conversation ->\", ps.stem(\"conversation\"))\n",
    "print(\"organization ->\", ps.stem(\"organization\"))\n",
    "print(\"studies ->\", ps.stem(\"studies\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d62b44c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d554e127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running -> running\n",
      "beautiful -> beautiful\n",
      "believes -> belief\n",
      "using -> using\n",
      "conversation -> conversation\n",
      "organization -> organization\n",
      "studies -> study\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wn = WordNetLemmatizer()\n",
    "\n",
    "print(\"running ->\", wn.lemmatize(\"running\"))\n",
    "print(\"beautiful ->\", wn.lemmatize(\"beautiful\"))\n",
    "print(\"believes ->\", wn.lemmatize(\"believes\"))\n",
    "print(\"using ->\", wn.lemmatize(\"using\"))\n",
    "print(\"conversation ->\", wn.lemmatize(\"conversation\"))\n",
    "print(\"organization ->\", wn.lemmatize(\"organization\"))\n",
    "print(\"studies ->\", wn.lemmatize(\"studies\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d1c47e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c09895df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c0e7e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_pos = [\"IN\", \"CC\", \"UH\", \"TO\", \"MD\", \"DT\", \"VBZ\", \"VBP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c568a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = \"https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/?sh=50f175be1f25\"\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "eng_news = soup.select(\".article-body p\")\n",
    "article = [p.text for p in eng_news[1:10]]\n",
    "text = \"\\n\".join(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16ee7fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens = word_tokenize(text)\n",
    "pos_tagged = pos_tag(word_tokens)\n",
    "len(pos_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c098dcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "for word, pos in pos_tagged:\n",
    "    if word.lower() not in stopwords.words('english') and pos not in stop_pos:\n",
    "        words.append(word)\n",
    "        \n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4a0d053e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['present-day',\n",
       " 'darling',\n",
       " 'tech',\n",
       " 'world',\n",
       " '.',\n",
       " 'current',\n",
       " 'renaissance',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " '(',\n",
       " 'AI',\n",
       " ')',\n",
       " 'sister',\n",
       " 'discipline',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " '(',\n",
       " 'ML',\n",
       " ')',\n",
       " 'led',\n",
       " 'firm',\n",
       " 'worth',\n",
       " 'salt',\n",
       " 'engineer',\n",
       " 'form',\n",
       " 'AI',\n",
       " 'platform',\n",
       " ',',\n",
       " 'toolsets',\n",
       " 'software',\n",
       " 'applications',\n",
       " '.',\n",
       " 'IBM',\n",
       " 'CEO',\n",
       " 'Ginni',\n",
       " 'Rometty',\n",
       " 'already',\n",
       " 'proclaimed',\n",
       " 'AI',\n",
       " 'change',\n",
       " '100',\n",
       " 'percent',\n",
       " 'jobs',\n",
       " 'next',\n",
       " 'decade',\n",
       " '.',\n",
       " ',',\n",
       " 'mean',\n",
       " 'everybody',\n",
       " \"'s\",\n",
       " 'job',\n",
       " 'mine',\n",
       " 'onward',\n",
       " 'role',\n",
       " 'grain',\n",
       " 'farmers',\n",
       " 'Egypt',\n",
       " ',',\n",
       " 'pastry',\n",
       " 'chefs',\n",
       " 'Paris',\n",
       " 'dog',\n",
       " 'walkers',\n",
       " 'Oregon',\n",
       " 'i.e',\n",
       " '.',\n",
       " 'job',\n",
       " '.',\n",
       " 'able',\n",
       " 'help',\n",
       " 'direct',\n",
       " 'workers',\n",
       " 'actions',\n",
       " 'behavior',\n",
       " 'new',\n",
       " 'degree',\n",
       " 'intelligence',\n",
       " 'predictive',\n",
       " 'analytics',\n",
       " ',',\n",
       " 'stemming',\n",
       " 'AI',\n",
       " 'increasingly',\n",
       " 'upon',\n",
       " '.',\n",
       " 'right',\n",
       " '?',\n",
       " 'AI',\n",
       " 'used',\n",
       " 'fanciful',\n",
       " 'notion',\n",
       " 'mostly',\n",
       " 'confined',\n",
       " 'science',\n",
       " 'fiction',\n",
       " ',',\n",
       " 'go',\n",
       " 'right',\n",
       " '?',\n",
       " 'recent',\n",
       " 'years',\n",
       " 'big',\n",
       " 'changes',\n",
       " 'technology',\n",
       " '.',\n",
       " 'Aside',\n",
       " 'proliferation',\n",
       " 'mobile',\n",
       " 'devices',\n",
       " 'impacted',\n",
       " 'us',\n",
       " ',',\n",
       " 'memory',\n",
       " 'become',\n",
       " 'lot',\n",
       " 'cheaper',\n",
       " ',',\n",
       " 'data',\n",
       " 'storage',\n",
       " 'become',\n",
       " 'lot',\n",
       " 'easier',\n",
       " '(',\n",
       " 'cloud',\n",
       " ',',\n",
       " 'elsewhere',\n",
       " ')',\n",
       " 'computer',\n",
       " 'processing',\n",
       " 'speeds',\n",
       " 'continued',\n",
       " 'outstrip',\n",
       " 'previous',\n",
       " 'records',\n",
       " '.',\n",
       " 'power',\n",
       " 'quantum',\n",
       " 'computing',\n",
       " 'corner',\n",
       " ',',\n",
       " 'AI',\n",
       " 'renaissance',\n",
       " 'simply',\n",
       " 'result',\n",
       " 'coming',\n",
       " 'together',\n",
       " '‘',\n",
       " 'tech',\n",
       " 'ingredient',\n",
       " '’',\n",
       " 'forces',\n",
       " '?',\n",
       " '“',\n",
       " \"n't\",\n",
       " 'massive',\n",
       " 'compute',\n",
       " 'power',\n",
       " '.',\n",
       " 'important',\n",
       " 'algorithmic',\n",
       " 'changes',\n",
       " 'developed',\n",
       " '.',\n",
       " ',',\n",
       " 'much',\n",
       " 'easier',\n",
       " 'gain',\n",
       " 'access',\n",
       " 'data',\n",
       " 'Internet-connected',\n",
       " 'world',\n",
       " ',',\n",
       " '”',\n",
       " 'said',\n",
       " 'Ted',\n",
       " 'Dunning',\n",
       " ',',\n",
       " 'CTO',\n",
       " 'data',\n",
       " 'platform',\n",
       " ',',\n",
       " 'AI',\n",
       " 'analytics',\n",
       " 'company',\n",
       " 'MapR',\n",
       " '.',\n",
       " '“',\n",
       " 'three',\n",
       " 'aspects',\n",
       " '(',\n",
       " 'compute',\n",
       " ',',\n",
       " 'algorithms',\n",
       " ',',\n",
       " 'data',\n",
       " ')',\n",
       " 'make',\n",
       " 'todays',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'possible',\n",
       " '.',\n",
       " 'Also',\n",
       " 'quite',\n",
       " 'frankly',\n",
       " ',',\n",
       " 'lot',\n",
       " 'applications',\n",
       " 'data',\n",
       " 'availability',\n",
       " '...',\n",
       " 'implemented',\n",
       " '25',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'pretty',\n",
       " 'easily',\n",
       " 'data',\n",
       " 'available',\n",
       " 'output',\n",
       " 'model',\n",
       " 'integrated',\n",
       " 'back',\n",
       " 'business',\n",
       " 'flow.',\n",
       " '”',\n",
       " ',',\n",
       " 'many',\n",
       " 'ways',\n",
       " ',',\n",
       " 'Dunning',\n",
       " 'really',\n",
       " 'modern',\n",
       " 'era',\n",
       " 'web',\n",
       " 'key',\n",
       " 'facilitator',\n",
       " 'new',\n",
       " 'age',\n",
       " 'AI',\n",
       " '.',\n",
       " 'Information',\n",
       " 'become',\n",
       " 'ubiquitous',\n",
       " ';',\n",
       " 'also',\n",
       " 'become',\n",
       " 'easier',\n",
       " 'access',\n",
       " 'accurately',\n",
       " 'classified',\n",
       " 'structured',\n",
       " ',',\n",
       " 'semi-structured',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " 'rawest',\n",
       " 'form',\n",
       " '.',\n",
       " 'Tuning',\n",
       " 'AI',\n",
       " 'towards',\n",
       " 'life']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eadb4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "97c29250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19),\n",
       " ('.', 14),\n",
       " ('AI', 9),\n",
       " ('data', 7),\n",
       " ('(', 4),\n",
       " (')', 4),\n",
       " ('become', 4),\n",
       " ('?', 3),\n",
       " ('lot', 3),\n",
       " ('easier', 3),\n",
       " ('tech', 2),\n",
       " ('world', 2),\n",
       " ('renaissance', 2),\n",
       " ('form', 2),\n",
       " ('platform', 2),\n",
       " ('applications', 2),\n",
       " ('job', 2),\n",
       " ('new', 2),\n",
       " ('analytics', 2),\n",
       " ('right', 2),\n",
       " ('years', 2),\n",
       " ('changes', 2),\n",
       " ('power', 2),\n",
       " ('“', 2),\n",
       " ('compute', 2),\n",
       " ('access', 2),\n",
       " ('”', 2),\n",
       " ('Dunning', 2),\n",
       " ('present-day', 1),\n",
       " ('darling', 1),\n",
       " ('current', 1),\n",
       " ('Artificial', 1),\n",
       " ('Intelligence', 1),\n",
       " ('sister', 1),\n",
       " ('discipline', 1),\n",
       " ('Machine', 1),\n",
       " ('Learning', 1),\n",
       " ('ML', 1),\n",
       " ('led', 1),\n",
       " ('firm', 1),\n",
       " ('worth', 1),\n",
       " ('salt', 1),\n",
       " ('engineer', 1),\n",
       " ('toolsets', 1),\n",
       " ('software', 1),\n",
       " ('IBM', 1),\n",
       " ('CEO', 1),\n",
       " ('Ginni', 1),\n",
       " ('Rometty', 1),\n",
       " ('already', 1),\n",
       " ('proclaimed', 1),\n",
       " ('change', 1),\n",
       " ('100', 1),\n",
       " ('percent', 1),\n",
       " ('jobs', 1),\n",
       " ('next', 1),\n",
       " ('decade', 1),\n",
       " ('mean', 1),\n",
       " ('everybody', 1),\n",
       " (\"'s\", 1),\n",
       " ('mine', 1),\n",
       " ('onward', 1),\n",
       " ('role', 1),\n",
       " ('grain', 1),\n",
       " ('farmers', 1),\n",
       " ('Egypt', 1),\n",
       " ('pastry', 1),\n",
       " ('chefs', 1),\n",
       " ('Paris', 1),\n",
       " ('dog', 1),\n",
       " ('walkers', 1),\n",
       " ('Oregon', 1),\n",
       " ('i.e', 1),\n",
       " ('able', 1),\n",
       " ('help', 1),\n",
       " ('direct', 1),\n",
       " ('workers', 1),\n",
       " ('actions', 1),\n",
       " ('behavior', 1),\n",
       " ('degree', 1),\n",
       " ('intelligence', 1),\n",
       " ('predictive', 1),\n",
       " ('stemming', 1),\n",
       " ('increasingly', 1),\n",
       " ('upon', 1),\n",
       " ('used', 1),\n",
       " ('fanciful', 1),\n",
       " ('notion', 1),\n",
       " ('mostly', 1),\n",
       " ('confined', 1),\n",
       " ('science', 1),\n",
       " ('fiction', 1),\n",
       " ('go', 1),\n",
       " ('recent', 1),\n",
       " ('big', 1),\n",
       " ('technology', 1),\n",
       " ('Aside', 1),\n",
       " ('proliferation', 1),\n",
       " ('mobile', 1),\n",
       " ('devices', 1),\n",
       " ('impacted', 1),\n",
       " ('us', 1),\n",
       " ('memory', 1),\n",
       " ('cheaper', 1),\n",
       " ('storage', 1),\n",
       " ('cloud', 1),\n",
       " ('elsewhere', 1),\n",
       " ('computer', 1),\n",
       " ('processing', 1),\n",
       " ('speeds', 1),\n",
       " ('continued', 1),\n",
       " ('outstrip', 1),\n",
       " ('previous', 1),\n",
       " ('records', 1),\n",
       " ('quantum', 1),\n",
       " ('computing', 1),\n",
       " ('corner', 1),\n",
       " ('simply', 1),\n",
       " ('result', 1),\n",
       " ('coming', 1),\n",
       " ('together', 1),\n",
       " ('‘', 1),\n",
       " ('ingredient', 1),\n",
       " ('’', 1),\n",
       " ('forces', 1),\n",
       " (\"n't\", 1),\n",
       " ('massive', 1),\n",
       " ('important', 1),\n",
       " ('algorithmic', 1),\n",
       " ('developed', 1),\n",
       " ('much', 1),\n",
       " ('gain', 1),\n",
       " ('Internet-connected', 1),\n",
       " ('said', 1),\n",
       " ('Ted', 1),\n",
       " ('CTO', 1),\n",
       " ('company', 1),\n",
       " ('MapR', 1),\n",
       " ('three', 1),\n",
       " ('aspects', 1),\n",
       " ('algorithms', 1),\n",
       " ('make', 1),\n",
       " ('todays', 1),\n",
       " ('machine', 1),\n",
       " ('learning', 1),\n",
       " ('possible', 1),\n",
       " ('Also', 1),\n",
       " ('quite', 1),\n",
       " ('frankly', 1),\n",
       " ('availability', 1),\n",
       " ('...', 1),\n",
       " ('implemented', 1),\n",
       " ('25', 1),\n",
       " ('ago', 1),\n",
       " ('pretty', 1),\n",
       " ('easily', 1),\n",
       " ('available', 1),\n",
       " ('output', 1),\n",
       " ('model', 1),\n",
       " ('integrated', 1),\n",
       " ('back', 1),\n",
       " ('business', 1),\n",
       " ('flow.', 1),\n",
       " ('many', 1),\n",
       " ('ways', 1),\n",
       " ('really', 1),\n",
       " ('modern', 1),\n",
       " ('era', 1),\n",
       " ('web', 1),\n",
       " ('key', 1),\n",
       " ('facilitator', 1),\n",
       " ('age', 1),\n",
       " ('Information', 1),\n",
       " ('ubiquitous', 1),\n",
       " (';', 1),\n",
       " ('also', 1),\n",
       " ('accurately', 1),\n",
       " ('classified', 1),\n",
       " ('structured', 1),\n",
       " ('semi-structured', 1),\n",
       " ('unstructured', 1),\n",
       " ('rawest', 1),\n",
       " ('Tuning', 1),\n",
       " ('towards', 1),\n",
       " ('life', 1)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a96ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = []\n",
    "for word in words:\n",
    "    stemmed_words.append(ps.stem(word))\n",
    "    \n",
    "lemmed_words = []\n",
    "for word in stemmed_words:\n",
    "    lemmed_words.append(wn.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "571df9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19),\n",
       " ('.', 14),\n",
       " ('ai', 9),\n",
       " ('data', 7),\n",
       " ('(', 4),\n",
       " (')', 4),\n",
       " ('becom', 4),\n",
       " ('comput', 4),\n",
       " ('chang', 3),\n",
       " ('job', 3),\n",
       " ('?', 3),\n",
       " ('lot', 3),\n",
       " ('easier', 3),\n",
       " ('tech', 2),\n",
       " ('world', 2),\n",
       " ('renaiss', 2),\n",
       " ('intellig', 2),\n",
       " ('machin', 2),\n",
       " ('learn', 2),\n",
       " ('form', 2),\n",
       " ('platform', 2),\n",
       " ('applic', 2),\n",
       " ('new', 2),\n",
       " ('analyt', 2),\n",
       " ('right', 2),\n",
       " ('year', 2),\n",
       " ('power', 2),\n",
       " ('“', 2),\n",
       " ('algorithm', 2),\n",
       " ('access', 2),\n",
       " ('”', 2),\n",
       " ('dun', 2),\n",
       " ('also', 2),\n",
       " ('avail', 2),\n",
       " ('present-day', 1),\n",
       " ('darl', 1),\n",
       " ('current', 1),\n",
       " ('artifici', 1),\n",
       " ('sister', 1),\n",
       " ('disciplin', 1),\n",
       " ('ml', 1),\n",
       " ('led', 1),\n",
       " ('firm', 1),\n",
       " ('worth', 1),\n",
       " ('salt', 1),\n",
       " ('engin', 1),\n",
       " ('toolset', 1),\n",
       " ('softwar', 1),\n",
       " ('ibm', 1),\n",
       " ('ceo', 1),\n",
       " ('ginni', 1),\n",
       " ('rometti', 1),\n",
       " ('alreadi', 1),\n",
       " ('proclaim', 1),\n",
       " ('100', 1),\n",
       " ('percent', 1),\n",
       " ('next', 1),\n",
       " ('decad', 1),\n",
       " ('mean', 1),\n",
       " ('everybodi', 1),\n",
       " (\"'s\", 1),\n",
       " ('mine', 1),\n",
       " ('onward', 1),\n",
       " ('role', 1),\n",
       " ('grain', 1),\n",
       " ('farmer', 1),\n",
       " ('egypt', 1),\n",
       " ('pastri', 1),\n",
       " ('chef', 1),\n",
       " ('pari', 1),\n",
       " ('dog', 1),\n",
       " ('walker', 1),\n",
       " ('oregon', 1),\n",
       " ('i.e', 1),\n",
       " ('abl', 1),\n",
       " ('help', 1),\n",
       " ('direct', 1),\n",
       " ('worker', 1),\n",
       " ('action', 1),\n",
       " ('behavior', 1),\n",
       " ('degre', 1),\n",
       " ('predict', 1),\n",
       " ('stem', 1),\n",
       " ('increasingli', 1),\n",
       " ('upon', 1),\n",
       " ('use', 1),\n",
       " ('fanci', 1),\n",
       " ('notion', 1),\n",
       " ('mostli', 1),\n",
       " ('confin', 1),\n",
       " ('scienc', 1),\n",
       " ('fiction', 1),\n",
       " ('go', 1),\n",
       " ('recent', 1),\n",
       " ('big', 1),\n",
       " ('technolog', 1),\n",
       " ('asid', 1),\n",
       " ('prolifer', 1),\n",
       " ('mobil', 1),\n",
       " ('devic', 1),\n",
       " ('impact', 1),\n",
       " ('u', 1),\n",
       " ('memori', 1),\n",
       " ('cheaper', 1),\n",
       " ('storag', 1),\n",
       " ('cloud', 1),\n",
       " ('elsewher', 1),\n",
       " ('process', 1),\n",
       " ('speed', 1),\n",
       " ('continu', 1),\n",
       " ('outstrip', 1),\n",
       " ('previou', 1),\n",
       " ('record', 1),\n",
       " ('quantum', 1),\n",
       " ('corner', 1),\n",
       " ('simpli', 1),\n",
       " ('result', 1),\n",
       " ('come', 1),\n",
       " ('togeth', 1),\n",
       " ('‘', 1),\n",
       " ('ingredi', 1),\n",
       " ('’', 1),\n",
       " ('forc', 1),\n",
       " (\"n't\", 1),\n",
       " ('massiv', 1),\n",
       " ('import', 1),\n",
       " ('develop', 1),\n",
       " ('much', 1),\n",
       " ('gain', 1),\n",
       " ('internet-connect', 1),\n",
       " ('said', 1),\n",
       " ('ted', 1),\n",
       " ('cto', 1),\n",
       " ('compani', 1),\n",
       " ('mapr', 1),\n",
       " ('three', 1),\n",
       " ('aspect', 1),\n",
       " ('make', 1),\n",
       " ('today', 1),\n",
       " ('possibl', 1),\n",
       " ('quit', 1),\n",
       " ('frankli', 1),\n",
       " ('...', 1),\n",
       " ('implement', 1),\n",
       " ('25', 1),\n",
       " ('ago', 1),\n",
       " ('pretti', 1),\n",
       " ('easili', 1),\n",
       " ('output', 1),\n",
       " ('model', 1),\n",
       " ('integr', 1),\n",
       " ('back', 1),\n",
       " ('busi', 1),\n",
       " ('flow.', 1),\n",
       " ('mani', 1),\n",
       " ('way', 1),\n",
       " ('realli', 1),\n",
       " ('modern', 1),\n",
       " ('era', 1),\n",
       " ('web', 1),\n",
       " ('key', 1),\n",
       " ('facilit', 1),\n",
       " ('age', 1),\n",
       " ('inform', 1),\n",
       " ('ubiquit', 1),\n",
       " (';', 1),\n",
       " ('accur', 1),\n",
       " ('classifi', 1),\n",
       " ('structur', 1),\n",
       " ('semi-structur', 1),\n",
       " ('unstructur', 1),\n",
       " ('rawest', 1),\n",
       " ('tune', 1),\n",
       " ('toward', 1),\n",
       " ('life', 1)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(lemmed_words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb3c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
