{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bb4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [(\"I love you\", \"P\"),\n",
    "        (\"love happy weekend\", \"P\"),\n",
    "        (\"bore work job\", \"N\"),\n",
    "        (\"I hate you\", \"N\"),\n",
    "        (\"bore weekend\", \"N\"),\n",
    "        (\"happy together\", \"P\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e1f92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "wordfreq = defaultdict(lambda : [0, 0])\n",
    "# wordfreq = {}\n",
    "print(wordfreq[\"award\"])\n",
    "\n",
    "\n",
    "wordfreq2 = {}\n",
    "wordfreq2[\"award\"] = [0, 0]\n",
    "wordfreq2[\"award\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615b4fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x000001B307A8CB88>, {'I': [1, 1], 'love': [2, 0], 'you': [1, 1], 'happy': [2, 0], 'weekend': [1, 1], 'bore': [0, 2], 'work': [0, 1], 'job': [0, 1], 'hate': [0, 1], 'together': [1, 0]})\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "positive_cnt  = 0\n",
    "nagative_cnt  = 0\n",
    "\n",
    "wordfreq = defaultdict(lambda : [0, 0])\n",
    "for doc, label in text:\n",
    "    words = doc.split()\n",
    "    label = 0 if label == \"P\" else 1\n",
    "    for word in words:\n",
    "        wordfreq[word][label] += 1\n",
    "        \n",
    "print(wordfreq)\n",
    "\n",
    "for key, (cnt0, cnt1) in wordfreq.items():\n",
    "    positive_cnt += cnt0\n",
    "    nagative_cnt += cnt1\n",
    "\n",
    "print(positive_cnt)\n",
    "print(nagative_cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11890b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'I': [0.16666666666666666, 0.16666666666666666],\n",
       "             'love': [0.2777777777777778, 0.05555555555555555],\n",
       "             'you': [0.16666666666666666, 0.16666666666666666],\n",
       "             'happy': [0.2777777777777778, 0.05555555555555555],\n",
       "             'weekend': [0.16666666666666666, 0.16666666666666666],\n",
       "             'bore': [0.05555555555555555, 0.2777777777777778],\n",
       "             'work': [0.05555555555555555, 0.16666666666666666],\n",
       "             'job': [0.05555555555555555, 0.16666666666666666],\n",
       "             'hate': [0.05555555555555555, 0.16666666666666666],\n",
       "             'together': [0.16666666666666666, 0.05555555555555555]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0.5\n",
    "wordprob = defaultdict(lambda : [0, 0])\n",
    "\n",
    "for key, (cnt0, cnt1) in wordfreq.items():\n",
    "    wordprob[key][0] = (k + cnt0 ) / ( 2*k + positive_cnt)\n",
    "    wordprob[key][1] = (k + cnt1 ) / ( 2*k + nagative_cnt)\n",
    "    \n",
    "wordprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d90c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def get_prob(doc):\n",
    "    tokens = doc.split()\n",
    "\n",
    "    log_prob0, log_prob1 = 0.0, 0.0\n",
    "\n",
    "    for word, (prob0, prob1) in wordprob.items():\n",
    "        if word in tokens:\n",
    "            log_prob0 += math.log(prob0)\n",
    "            log_prob1 += math.log(prob1)\n",
    "\n",
    "    log_prob0 += math.log(positive_cnt / (positive_cnt + nagative_cnt))\n",
    "    log_prob1 += math.log(nagative_cnt / (positive_cnt + nagative_cnt))\n",
    "\n",
    "    prob0 = math.exp(log_prob0)\n",
    "    prob1 = math.exp(log_prob1)\n",
    "    \n",
    "    return prob0, prob1\n",
    "\n",
    "\n",
    "doc = \"happy weekend\"\n",
    "prob0, prob1 = get_prob(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0afbd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023148148148148143 0.0046296296296296285\n"
     ]
    }
   ],
   "source": [
    "print(prob0, prob1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49afd331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상 확률 83.3%\n",
      "스팸 확률 16.7%\n"
     ]
    }
   ],
   "source": [
    "print(\"정상 확률 {:.1f}%\".format((prob0 / (prob0 + prob1)) * 100))\n",
    "print(\"스팸 확률 {:.1f}%\".format((prob1 / (prob0 + prob1)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee114a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b0841ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love you',\n",
       " 'love happy weekend',\n",
       " 'bore work job',\n",
       " 'I hate you',\n",
       " 'bore weekend',\n",
       " 'happy together']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [t[0] for t in text]\n",
    "y_train = [t[1] for t in text]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8292a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P', 'P', 'N', 'N', 'N', 'P']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36fdd87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f7dd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['P'], dtype='<U1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(count_vectorizer.transform([\"happy weekend\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4962bc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.75]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(count_vectorizer.transform([\"happy weekend\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b93042d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        200000 non-null  int64 \n",
      " 1   document  199992 non-null  object\n",
      " 2   label     200000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", sep=\"\\t\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eea41ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 199992 entries, 0 to 199999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        199992 non-null  int64 \n",
      " 1   document  199992 non-null  object\n",
      " 2   label     199992 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ce47394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bf91967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186420    진짜요즘런닝맨 개재미없네요 쓸떼없이 게스트 쳐부르지말고 그냥 멤버끼리만하면안됨?? ...\n",
       "42641                너무 재밌고 감동 ㅠㅠ 그루 츤데레 그리고 미니언들 너무너무너무귀엽다\n",
       "110059                    스토리는 천군보다 나은데....연출이나 연기 참 못한다...\n",
       "66757                                  분위기에 취해 버리게 만드는 영화..\n",
       "164593                                           노잼노잼노잼노잼노잼\n",
       "56451                               이렇게재밌는영화를보면리뷰를남기는게예의겟지?\n",
       "130924                                        아.. 어쩌란 말이냐..\n",
       "26836                                세실리아와 로비의 사랑이 너무 안타깝네요\n",
       "67863                                        두 배우 넘 조합이 좋다!\n",
       "145657                                         말이 필요없는 쓰레기.\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['document'], df['label'], shuffle=True, random_state=42)\n",
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8506a0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186420    0\n",
       "42641     1\n",
       "110059    0\n",
       "66757     1\n",
       "164593    0\n",
       "56451     1\n",
       "130924    0\n",
       "26836     1\n",
       "67863     1\n",
       "145657    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d412ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_count = count_vect.fit_transform(X_train)\n",
    "clf = MultinomialNB().fit(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b79c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8304132165286612"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_count = count_vect.transform(X_test)\n",
    "predicted = clf.predict(X_text_count)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc7922ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))), ('tfidf', TfidfTransformer()), \n",
    "                     ('clf', MultinomialNB(alpha=0.5))])\n",
    "\n",
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57e0dc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8350934037361495"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92835dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_clf = {\"vect__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "             \"clf__alpha\": (1, 0.5, 0.1, 0.001)}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, params_clf, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e0416e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf : MultinomialNB(alpha=0.5)\n",
      "clf__alpha : 0.5\n",
      "clf__class_prior : None\n",
      "clf__fit_prior : True\n",
      "memory : None\n",
      "steps : [('vect', CountVectorizer(ngram_range=(1, 2))), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB(alpha=0.5))]\n",
      "tfidf : TfidfTransformer()\n",
      "tfidf__norm : l2\n",
      "tfidf__smooth_idf : True\n",
      "tfidf__sublinear_tf : False\n",
      "tfidf__use_idf : True\n",
      "vect : CountVectorizer(ngram_range=(1, 2))\n",
      "vect__analyzer : word\n",
      "vect__binary : False\n",
      "vect__decode_error : strict\n",
      "vect__dtype : <class 'numpy.int64'>\n",
      "vect__encoding : utf-8\n",
      "vect__input : content\n",
      "vect__lowercase : True\n",
      "vect__max_df : 1.0\n",
      "vect__max_features : None\n",
      "vect__min_df : 1\n",
      "vect__ngram_range : (1, 2)\n",
      "vect__preprocessor : None\n",
      "vect__stop_words : None\n",
      "vect__strip_accents : None\n",
      "vect__token_pattern : (?u)\\b\\w\\w+\\b\n",
      "vect__tokenizer : None\n",
      "vect__vocabulary : None\n",
      "verbose : False\n"
     ]
    }
   ],
   "source": [
    "best_paramters = gs_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(list(best_paramters.keys())):\n",
    "    print(\"{} : {}\".format(param_name, best_paramters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "415ca999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8350934037361495"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = gs_clf.best_estimator_.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a9b1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dict = {}\n",
    "with open(\"pos_pol_word.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sent_dict[\"pos\"] =f.read().split(\"\\n\")[19:]\n",
    "    \n",
    "with open(\"neg_pol_word.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sent_dict[\"neg\"] =f.read().split(\"\\n\")[19:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe9ed016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(-;', '(^^)', '(^-^)', '(^^*', '(^_^)', '(^o^)', '*^^*', '/^o^\\\\', ':(', \":'-(\"]\n",
      "\n",
      "\n",
      "\n",
      "['가난', '가난뱅이', '가난살이', '가난살이하다', '가난설음', '가난에', '가난에 쪼들려서', '가난하게', '가난하고', '가난하고 어렵다']\n"
     ]
    }
   ],
   "source": [
    "print(sent_dict[\"pos\"][:10])\n",
    "print(\"\\n\\n\")\n",
    "print(sent_dict[\"neg\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9a4fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"코로나19의 여파로 전 세계 교사들과 학생들 모두 혼란스러운 시기를 보내고 있습니다. 초유의 상황에서도, 학생들을 위해 최선을 다하려는 선생님들의 노력이 계속되고 있는데요. 어려움 속에서, 선생님들은 어떤 방법으로 사랑을 전하고 있을까요? 뉴스G에서 전해드립니다. [리포트] 중국 저장성의 한 산골 마을. 초등학교 교사 왕진량 씨는 지난 2월 말부터, 매일 새벽 다섯 시면 부지런히 집을 나섭니다. 온라인 수업을 받을 수 없는, 깊은 산골 마을에 살고 있는 학생들을 찾아가기 위해서인데요. 선생님이 하루 동안 이동하는 거리는 대략 30km정도. 차도 없이 도보로 네 개의 마을을 돌아다니며 학생들을 만납니다. 매일 이어지는 강행군이지만, 오로지 아이들의 학습이 중단되어서는 안 된다는 생각뿐입니다. 혹시 모를 사태에 대비해 학생들과의 접촉은 최대한 줄입니다. 숙제를 내주고, 검사 후에 모르는 문제를 알려주는 식으로 일대일 수업을 진행하고 있는데요. 아이들에게 배우는 즐거움이 얼마나 소중한 것인지 잘 알기에, 선생님은 이렇게라도 수업을 할 수 있다는 데서 행복을 느낍니다. 영국의 한 초등학교 교사인 젠 포울스 씨는 매일 아침, 무거운 짐을 앞 뒤, 양 옆으로 짊어지고 씩씩하게 발걸음을 옮깁니다. 코로나19로 학교가 문을 닫은 뒤, 형편이 어려운 학생들을 위해 매일 78인분의 점심 도시락을 배달하고 있는데요. 선생님이 재직 중인 초등학교는 전체 학생의 41퍼센트가 무상 급식 대상자이기 때문입니다. 도시락의 무게는 18kg, 걸어야 하는 거리는 8km에 달하지만 기다리는 학생들을 생각하며 지치지 않고 발걸음을 재촉합니다. 학생들은 창문을 통해서 반갑게 인사하기도 하고, 선생님이 볼 수 있게 감사 메시지를 붙여 놓기도 하는데요. 선생님이 정성껏 준비해 손수 배달한 사랑의 도시락. 봉쇄된 도시의 굶주린 아이들에게 소중한 한 끼 식사, 그 이상의 의미가 되고 있습니다. 미국 사우스다코타 주의 중학교 수학 교사인 크리스 와바 씨는, 커다란 화이트보드를 들고 학생의 집을 찾았습니다. 온라인 수업 후, 학생에게 이메일로 방정식 풀이법에 대한 질문을 받았기 때문인데요. 이메일로 답변해주는 것보다 직접 풀이 과정을 보여주는 게 낫다는 생각이었죠. 깜짝 놀란 학생을 마주한 채, 선생님은 현관문 앞에서 열정적으로 문제를 풀기 시작했습니다. 이 열정적인 강의는, 학생이 풀이법을 완벽히 이해할 때까지 이어졌는데요. 바이러스는 전 세계 교실에 혼란을 불러왔지만, 선생님들의 노력은 저마다의 방식으로 계속되고 있습니다. 어려움 속에서도 학생들을 위해 안간힘을 쓰고 있는 모든 선생님들에게, 응원과 박수를 함께 보냅니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6f9e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "def analyze_sentiment(text, sent_dict):\n",
    "    pos = []\n",
    "    neg = []\n",
    "    \n",
    "    word_list = text.split()\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word in sent_dict[\"pos\"]:\n",
    "            pos.append(word)\n",
    "            \n",
    "        if word in sent_dict[\"neg\"]:\n",
    "            neg.append(word)\n",
    "            \n",
    "    return (len(pos)/(len(pos) + len(neg)), pos) , (len(neg)/(len(pos) + len(neg)), neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cb942c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6666666666666666, ['사랑을', '부지런히', '즐거움이', '소중한', '잘', '행복을', '씩씩하게', '감사', '정성껏', '사랑의', '소중한', '함께']) (0.3333333333333333, ['혼란스러운', '어려움', '모르는', '어려운', '굶주린', '어려움'])\n"
     ]
    }
   ],
   "source": [
    "pos, neg = analyze_sentiment(txt, sent_dict)\n",
    "print(pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d231ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fd1e06af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(columns=['calory', 'breakfast', 'lunch', 'dinner', 'exercise', 'body_shape'])\n",
    "\n",
    "df.loc[0] = [1200, 1, 0, 0, 2, 'Skinny']\n",
    "df.loc[1] = [2800, 1, 1, 1, 1, 'Normal']\n",
    "df.loc[2] = [3500, 2, 2, 1, 0, 'Fat']\n",
    "df.loc[3] = [1400, 0, 1, 0, 3, 'Skinny']\n",
    "df.loc[4] = [5000, 2, 2, 2, 0, 'Fat']\n",
    "df.loc[5] = [1300, 0, 0, 1, 2, 'Skinny']\n",
    "df.loc[6] = [3000, 1, 0, 1, 1, 'Normal']\n",
    "df.loc[7] = [4000, 2, 2, 2, 0, 'Fat']\n",
    "df.loc[8] = [2600, 0, 2, 0, 0, 'Normal']\n",
    "df.loc[9] = [3000, 1, 2, 1, 1, 'Fat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b8ced7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[9] = [3000, 1, 2, 1, 1, 'Fat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "32496d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['calory', 'breakfast', 'lunch', 'dinner', 'exercise']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2dbb3a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.35205803,  0.        , -1.3764944 , -1.28571429,  1.        ],\n",
       "       [ 0.01711466,  0.        , -0.22941573,  0.14285714,  0.        ],\n",
       "       [ 0.61612771,  1.29099445,  0.91766294,  0.14285714, -1.        ],\n",
       "       [-1.18091145, -1.29099445, -0.22941573, -1.28571429,  2.        ],\n",
       "       [ 1.89972711,  1.29099445,  0.91766294,  1.57142857, -1.        ],\n",
       "       [-1.26648474, -1.29099445, -1.3764944 ,  0.14285714,  1.        ],\n",
       "       [ 0.18826125,  0.        , -1.3764944 ,  0.14285714,  0.        ],\n",
       "       [ 1.04399418,  1.29099445,  0.91766294,  1.57142857, -1.        ],\n",
       "       [-0.15403193, -1.29099445,  0.91766294, -1.28571429, -1.        ],\n",
       "       [ 0.18826125,  0.        ,  0.91766294,  0.14285714,  0.        ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8ae19c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.552713678800501e-17"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "45964d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d3f31a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "96415e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.11111111,  0.88379717,  0.76782385,  0.89376551, -0.93179808],\n",
       "       [ 0.88379717,  1.11111111,  0.49362406,  0.81967902, -0.71721914],\n",
       "       [ 0.76782385,  0.49362406,  1.11111111,  0.40056715, -0.76471911],\n",
       "       [ 0.89376551,  0.81967902,  0.40056715,  1.11111111, -0.63492063],\n",
       "       [-0.93179808, -0.71721914, -0.76471911, -0.63492063,  1.11111111]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = x_std.T\n",
    "covariance_matrix = np.cov(features)\n",
    "\n",
    "covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fdec1a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.11111111,  0.88379717,  0.76782385,  0.89376551, -0.93179808],\n",
       "       [ 0.88379717,  1.11111111,  0.49362406,  0.81967902, -0.71721914],\n",
       "       [ 0.76782385,  0.49362406,  1.11111111,  0.40056715, -0.76471911],\n",
       "       [ 0.89376551,  0.81967902,  0.40056715,  1.11111111, -0.63492063],\n",
       "       [-0.93179808, -0.71721914, -0.76471911, -0.63492063,  1.11111111]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std.T.dot(x_std)/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d96a8bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eig values \n",
      " [4.0657343  0.8387565  0.07629538 0.27758568 0.2971837 ]\n",
      "eig vectors \n",
      " [[-0.508005   -0.0169937  -0.84711404  0.11637853  0.10244985]\n",
      " [-0.44660335 -0.36890361  0.12808055 -0.63112016 -0.49973822]\n",
      " [-0.38377913  0.70804084  0.20681005 -0.40305226  0.38232213]\n",
      " [-0.42845209 -0.53194699  0.3694462   0.22228235  0.58954327]\n",
      " [ 0.46002038 -0.2816592  -0.29450345 -0.61341895  0.49601841]]\n"
     ]
    }
   ],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(covariance_matrix)\n",
    "print(\"eig values \\n\", eig_vals)\n",
    "print(\"eig vectors \\n\", eig_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "33cfc129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7318321731427544"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_vals[0]/sum(eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2047595b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361675b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5fda507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_X = x_std.dot(eig_vecs.T[0]) #eigenvcetor 가 가장 큰 벡터에 사형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9bee4ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages (from seaborn) (1.7.3)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages (from seaborn) (1.3.5)\n",
      "Collecting matplotlib>=2.2\n",
      "  Downloading matplotlib-3.5.1-cp37-cp37m-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp37-cp37m-win_amd64.whl (51 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.0.1-cp37-cp37m-win_amd64.whl (3.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.29.1-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib, seaborn\n",
      "Successfully installed cycler-0.11.0 fonttools-4.29.1 kiwisolver-1.3.2 matplotlib-3.5.1 pillow-9.0.1 seaborn-0.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "236cea9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18152\\3726815570.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlmplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PC1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y-axis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscatter_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"s\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.lmplot('PC1', 'y-axis', data=result, fit_reg=False, scatter_kws={\"s\":50}, hue='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "631c593a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18152\\3845090024.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpca_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpca_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pca_' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA(n_components=1)\n",
    "pca_x = pca_.fit_transform(x_std)\n",
    "pca_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "47a17027",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18152\\829757143.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msklearn_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"PC1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msklearn_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y-axis'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msklearn_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlmplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PC1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y-axis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscatter_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"s\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             raise AttributeError(\"module {!r} has no attribute \"\n\u001b[1;32m--> 314\u001b[1;33m                                  \"{!r}\".format(__name__, attr))\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'DataFrame'"
     ]
    }
   ],
   "source": [
    "sklearn_result = pd.DataFrame(pca_x, columns=[\"PC1\"])\n",
    "sklearn_result['y-axis'] = 0.0\n",
    "sklearn_result['label'] = Y\n",
    "\n",
    "sns.lmplot('PC1', 'y-axis', data=result, fit_reg=False, scatter_kws={\"s\":50}, hue='label')\n",
    "plt.title('PCA result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ed3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
