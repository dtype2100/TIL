{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtype2100/TIL/blob/master/0121_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb5bef7-5c3e-46d7-93fd-a0f767043cfb",
      "metadata": {
        "id": "1cb5bef7-5c3e-46d7-93fd-a0f767043cfb"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e29338c-cefb-4f6a-8f64-e39419e8d7a7",
      "metadata": {
        "id": "6e29338c-cefb-4f6a-8f64-e39419e8d7a7",
        "outputId": "32c2d9dd-2219-4e41-c2c4-028ed499c89c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"words\")\n",
        "nltk.download(\"maxent_ne_chunker\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "756cf605-5be2-4a14-92de-8213ccb85382",
      "metadata": {
        "id": "756cf605-5be2-4a14-92de-8213ccb85382"
      },
      "outputs": [],
      "source": [
        "text = 'Good muffins cost $3.88\\nin New York. Please buy me\\ntwo of them.\\n\\nThanks.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12de814d-16c6-49e1-bf08-22a199bac2d6",
      "metadata": {
        "id": "12de814d-16c6-49e1-bf08-22a199bac2d6"
      },
      "outputs": [],
      "source": [
        "from nltk import ne_chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f53976-9ef5-46c0-93e1-0756049ec52a",
      "metadata": {
        "id": "04f53976-9ef5-46c0-93e1-0756049ec52a",
        "outputId": "e0b5626d-2719-4232-adb6-a92c0d3565c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[1;31mSignature:\u001b[0m \u001b[0mne_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagged_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
              "\u001b[1;31mDocstring:\u001b[0m\n",
              "Use NLTK's currently recommended named entity chunker to\n",
              "chunk the given list of tagged tokens.\n",
              "\u001b[1;31mFile:\u001b[0m      c:\\users\\student\\anaconda3\\envs\\nlp\\lib\\site-packages\\nltk\\chunk\\__init__.py\n",
              "\u001b[1;31mType:\u001b[0m      function\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ne_chunk?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9780dcf-decc-48af-90ca-f1fa6c4c731e",
      "metadata": {
        "id": "e9780dcf-decc-48af-90ca-f1fa6c4c731e"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_tokens = word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8cdf7d9-b5c8-4ac6-8812-9d4db3bbd4ae",
      "metadata": {
        "id": "c8cdf7d9-b5c8-4ac6-8812-9d4db3bbd4ae",
        "outputId": "792f1b5a-f944-4938-fea9-22ce5161867a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Good',\n",
              " 'muffins',\n",
              " 'cost',\n",
              " '$',\n",
              " '3.88',\n",
              " 'in',\n",
              " 'New',\n",
              " 'York',\n",
              " '.',\n",
              " 'Please',\n",
              " 'buy',\n",
              " 'me',\n",
              " 'two',\n",
              " 'of',\n",
              " 'them',\n",
              " '.',\n",
              " 'Thanks',\n",
              " '.']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ae92383-adda-42c5-9d75-9ea05442d3ca",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "3ae92383-adda-42c5-9d75-9ea05442d3ca",
        "outputId": "439f4795-69b7-4181-f5ad-145d601f1a48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Good', 'JJ'),\n",
              " ('muffins', 'NNS'),\n",
              " ('cost', 'VBP'),\n",
              " ('$', '$'),\n",
              " ('3.88', 'CD'),\n",
              " ('in', 'IN'),\n",
              " ('New', 'NNP'),\n",
              " ('York', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Please', 'NNP'),\n",
              " ('buy', 'VB'),\n",
              " ('me', 'PRP'),\n",
              " ('two', 'CD'),\n",
              " ('of', 'IN'),\n",
              " ('them', 'PRP'),\n",
              " ('.', '.'),\n",
              " ('Thanks', 'NNS'),\n",
              " ('.', '.')]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk import pos_tag\n",
        "pos_tagged = pos_tag(word_tokens)\n",
        "pos_tagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9b55b5-8373-48d4-b39b-abcbd1f15427",
      "metadata": {
        "id": "ac9b55b5-8373-48d4-b39b-abcbd1f15427",
        "outputId": "2924c8c1-e151-4b66-e99d-40b52e9b94eb"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,760.0,168.0\" width=\"760px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"6.31579%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Good</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.15789%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"9.47368%\" x=\"6.31579%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">muffins</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.0526%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.31579%\" x=\"15.7895%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cost</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.9474%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"22.1053%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">$</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"23.6842%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.31579%\" x=\"25.2632%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">3.88</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.4211%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.21053%\" x=\"31.5789%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"33.6842%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"11.5789%\" x=\"35.7895%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">GPE</text></svg><svg width=\"45.4545%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">New</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"54.5455%\" x=\"45.4545%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">York</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.7273%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"41.5789%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"47.3684%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.9474%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"8.42105%\" x=\"50.5263%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Please</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.7368%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.26316%\" x=\"58.9474%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">buy</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.5789%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.26316%\" x=\"64.2105%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">me</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.8421%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.26316%\" x=\"69.4737%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">two</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.1053%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.21053%\" x=\"74.7368%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"76.8421%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.31579%\" x=\"78.9474%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">them</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.1053%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"85.2632%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"86.8421%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"8.42105%\" x=\"88.4211%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Thanks</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.6316%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.15789%\" x=\"96.8421%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.4211%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
            ],
            "text/plain": [
              "Tree('S', [Tree('GPE', [('Good', 'JJ')]), ('muffins', 'NNS'), ('cost', 'VBP'), ('$', '$'), ('3.88', 'CD'), ('in', 'IN'), Tree('GPE', [('New', 'NNP'), ('York', 'NNP')]), ('.', '.'), ('Please', 'NNP'), ('buy', 'VB'), ('me', 'PRP'), ('two', 'CD'), ('of', 'IN'), ('them', 'PRP'), ('.', '.'), ('Thanks', 'NNS'), ('.', '.')])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ne_tokens = ne_chunk(pos_tagged)\n",
        "ne_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f843bb4e-b8ea-444d-ba25-e8209e8b5c47",
      "metadata": {
        "id": "f843bb4e-b8ea-444d-ba25-e8209e8b5c47",
        "outputId": "0f32b423-a7d0-4539-f1d1-c8f06ec59771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (GPE Good/JJ)\n",
            "  muffins/NNS\n",
            "  cost/VBP\n",
            "  $/$\n",
            "  3.88/CD\n",
            "  in/IN\n",
            "  (GPE New/NNP York/NNP)\n",
            "  ./.\n",
            "  Please/NNP\n",
            "  buy/VB\n",
            "  me/PRP\n",
            "  two/CD\n",
            "  of/IN\n",
            "  them/PRP\n",
            "  ./.\n",
            "  Thanks/NNS\n",
            "  ./.)\n"
          ]
        }
      ],
      "source": [
        "print(ne_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38de3926-b92c-428d-9a3a-164a1651e558",
      "metadata": {
        "id": "38de3926-b92c-428d-9a3a-164a1651e558"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "956a86ae-8692-4385-90a3-94f3de61f108",
      "metadata": {
        "id": "956a86ae-8692-4385-90a3-94f3de61f108",
        "outputId": "906cd4b2-4925-4a51-83e1-37d5225d524c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3.88, New York, two)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc.ents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db4dbc2d-8241-47a7-9379-f72c0d0327c5",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "db4dbc2d-8241-47a7-9379-f72c0d0327c5",
        "outputId": "b76f0edc-065a-4f75-8b66-295088685fa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Good ADJ\n",
            "muffins NOUN\n",
            "cost VERB\n",
            "$ SYM\n",
            "3.88 NUM\n",
            "\n",
            " SPACE\n",
            "in ADP\n",
            "New PROPN\n",
            "York PROPN\n",
            ". PUNCT\n",
            "Please INTJ\n",
            "buy VERB\n",
            "me PRON\n",
            "\n",
            " SPACE\n",
            "two NUM\n",
            "of ADP\n",
            "them PRON\n",
            ". PUNCT\n",
            "\n",
            "\n",
            " SPACE\n",
            "Thanks X\n",
            ". PUNCT\n"
          ]
        }
      ],
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.pos_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2303c19e-355e-4617-859a-e8b41944937f",
      "metadata": {
        "id": "2303c19e-355e-4617-859a-e8b41944937f",
        "outputId": "5e08a0b7-f298-466f-f302-f644453a6795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running -> run\n",
            "beautiful -> beauti\n",
            "believes -> believ\n",
            "using -> use\n",
            "conversation -> convers\n",
            "organization -> organ\n",
            "studies -> studi\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "print(\"running ->\", ps.stem(\"running\"))\n",
        "print(\"beautiful ->\", ps.stem(\"beautiful\"))\n",
        "print(\"believes ->\", ps.stem(\"believes\"))\n",
        "print(\"using ->\", ps.stem(\"using\"))\n",
        "print(\"conversation ->\", ps.stem(\"conversation\"))\n",
        "print(\"organization ->\", ps.stem(\"organization\"))\n",
        "print(\"studies ->\", ps.stem(\"studies\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb8f4eb-87f8-403e-8f00-d4ec08fa8629",
      "metadata": {
        "id": "2eb8f4eb-87f8-403e-8f00-d4ec08fa8629",
        "outputId": "3a28d3d5-9bb8-42e1-9b37-831008ac5070"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"wordnet\")\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1faab4-4a56-454c-82cd-cc96223d4b8f",
      "metadata": {
        "id": "af1faab4-4a56-454c-82cd-cc96223d4b8f",
        "outputId": "61b07ac8-9959-4eef-9cd6-fe22e662f87b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running -> running\n",
            "beautiful -> beautiful\n",
            "believes -> belief\n",
            "using -> using\n",
            "conversation -> conversation\n",
            "organization -> organization\n",
            "studies -> study\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wn = WordNetLemmatizer()\n",
        "\n",
        "print(\"running ->\", wn.lemmatize(\"running\"))\n",
        "print(\"beautiful ->\", wn.lemmatize(\"beautiful\"))\n",
        "print(\"believes ->\", wn.lemmatize(\"believes\"))\n",
        "print(\"using ->\", wn.lemmatize(\"using\"))\n",
        "print(\"conversation ->\", wn.lemmatize(\"conversation\"))\n",
        "print(\"organization ->\", wn.lemmatize(\"organization\"))\n",
        "print(\"studies ->\", wn.lemmatize(\"studies\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f33369a-2fa1-4af4-8c15-998657bf8e9b",
      "metadata": {
        "id": "6f33369a-2fa1-4af4-8c15-998657bf8e9b",
        "outputId": "0a09136b-f885-48a9-8f54-f4f8bb1f6293"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc85d431-af4c-4cdd-a29b-79837c5bf485",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "dc85d431-af4c-4cdd-a29b-79837c5bf485",
        "outputId": "875c6ec6-9e47-4b84-be97-b79e8acfcc83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24b2a8e8-598b-46ea-a876-c77455b0f3bf",
      "metadata": {
        "id": "24b2a8e8-598b-46ea-a876-c77455b0f3bf"
      },
      "outputs": [],
      "source": [
        "stop_pos = [\"IN\", \"CC\", \"UH\", \"TO\", \"MD\", \"DT\", \"VBZ\", \"VBP\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4405e371-b57f-453b-9833-44a8a0be9c8c",
      "metadata": {
        "id": "4405e371-b57f-453b-9833-44a8a0be9c8c"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/?sh=241229d11f25\"\n",
        "resp = requests.get(url)\n",
        "soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "eng_news = soup.select(\".article-body p\")\n",
        "article  = [p.text for p in eng_news[1:10]]\n",
        "text = \"\\n\".join(article)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e43bc78-e2ea-4540-adce-62f5644da48a",
      "metadata": {
        "id": "9e43bc78-e2ea-4540-adce-62f5644da48a",
        "outputId": "275ed0c2-55a5-4435-89e7-fb81687bc2fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "445"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens = word_tokenize(text)\n",
        "pos_tagged = pos_tag(word_tokens)\n",
        "len(pos_tagged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d60bb5a-3547-4356-a639-4dafc987f760",
      "metadata": {
        "id": "5d60bb5a-3547-4356-a639-4dafc987f760",
        "outputId": "098d229d-de47-408e-c5ce-a3a3764a210e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "263"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = []\n",
        "\n",
        "for word, pos in pos_tagged:\n",
        "    if word.lower() not in stopwords.words('english') and pos not in stop_pos:\n",
        "        words.append(word)\n",
        "        \n",
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65906b9e-e4d1-4b42-8d40-77c2521880cf",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "65906b9e-e4d1-4b42-8d40-77c2521880cf",
        "outputId": "ebfe18e6-51b1-4833-9d5f-c6ba12caefa6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['present-day',\n",
              " 'darling',\n",
              " 'tech',\n",
              " 'world',\n",
              " '.',\n",
              " 'current',\n",
              " 'renaissance',\n",
              " 'Artificial',\n",
              " 'Intelligence',\n",
              " '(',\n",
              " 'AI',\n",
              " ')',\n",
              " 'sister',\n",
              " 'discipline',\n",
              " 'Machine',\n",
              " 'Learning',\n",
              " '(',\n",
              " 'ML',\n",
              " ')',\n",
              " 'led',\n",
              " 'firm',\n",
              " 'worth',\n",
              " 'salt',\n",
              " 'engineer',\n",
              " 'form',\n",
              " 'AI',\n",
              " 'platform',\n",
              " ',',\n",
              " 'toolsets',\n",
              " 'software',\n",
              " 'applications',\n",
              " '.',\n",
              " 'IBM',\n",
              " 'CEO',\n",
              " 'Ginni',\n",
              " 'Rometty',\n",
              " 'already',\n",
              " 'proclaimed',\n",
              " 'AI',\n",
              " 'change',\n",
              " '100',\n",
              " 'percent',\n",
              " 'jobs',\n",
              " 'next',\n",
              " 'decade',\n",
              " '.',\n",
              " ',',\n",
              " 'mean',\n",
              " 'everybody',\n",
              " \"'s\",\n",
              " 'job',\n",
              " 'mine',\n",
              " 'onward',\n",
              " 'role',\n",
              " 'grain',\n",
              " 'farmers',\n",
              " 'Egypt',\n",
              " ',',\n",
              " 'pastry',\n",
              " 'chefs',\n",
              " 'Paris',\n",
              " 'dog',\n",
              " 'walkers',\n",
              " 'Oregon',\n",
              " 'i.e',\n",
              " '.',\n",
              " 'job',\n",
              " '.',\n",
              " 'able',\n",
              " 'help',\n",
              " 'direct',\n",
              " 'workers',\n",
              " 'actions',\n",
              " 'behavior',\n",
              " 'new',\n",
              " 'degree',\n",
              " 'intelligence',\n",
              " 'predictive',\n",
              " 'analytics',\n",
              " ',',\n",
              " 'stemming',\n",
              " 'AI',\n",
              " 'increasingly',\n",
              " 'upon',\n",
              " '.',\n",
              " 'right',\n",
              " '?',\n",
              " 'AI',\n",
              " 'used',\n",
              " 'fanciful',\n",
              " 'notion',\n",
              " 'mostly',\n",
              " 'confined',\n",
              " 'science',\n",
              " 'fiction',\n",
              " ',',\n",
              " 'go',\n",
              " 'right',\n",
              " '?',\n",
              " 'recent',\n",
              " 'years',\n",
              " 'big',\n",
              " 'changes',\n",
              " 'technology',\n",
              " '.',\n",
              " 'Aside',\n",
              " 'proliferation',\n",
              " 'mobile',\n",
              " 'devices',\n",
              " 'impacted',\n",
              " 'us',\n",
              " ',',\n",
              " 'memory',\n",
              " 'become',\n",
              " 'lot',\n",
              " 'cheaper',\n",
              " ',',\n",
              " 'data',\n",
              " 'storage',\n",
              " 'become',\n",
              " 'lot',\n",
              " 'easier',\n",
              " '(',\n",
              " 'cloud',\n",
              " ',',\n",
              " 'elsewhere',\n",
              " ')',\n",
              " 'computer',\n",
              " 'processing',\n",
              " 'speeds',\n",
              " 'continued',\n",
              " 'outstrip',\n",
              " 'previous',\n",
              " 'records',\n",
              " '.',\n",
              " 'power',\n",
              " 'quantum',\n",
              " 'computing',\n",
              " 'corner',\n",
              " ',',\n",
              " 'AI',\n",
              " 'renaissance',\n",
              " 'simply',\n",
              " 'result',\n",
              " 'coming',\n",
              " 'together',\n",
              " '‘',\n",
              " 'tech',\n",
              " 'ingredient',\n",
              " '’',\n",
              " 'forces',\n",
              " '?',\n",
              " '“',\n",
              " \"n't\",\n",
              " 'massive',\n",
              " 'compute',\n",
              " 'power',\n",
              " '.',\n",
              " 'important',\n",
              " 'algorithmic',\n",
              " 'changes',\n",
              " 'developed',\n",
              " '.',\n",
              " ',',\n",
              " 'much',\n",
              " 'easier',\n",
              " 'gain',\n",
              " 'access',\n",
              " 'data',\n",
              " 'Internet-connected',\n",
              " 'world',\n",
              " ',',\n",
              " '”',\n",
              " 'said',\n",
              " 'Ted',\n",
              " 'Dunning',\n",
              " ',',\n",
              " 'CTO',\n",
              " 'data',\n",
              " 'platform',\n",
              " ',',\n",
              " 'AI',\n",
              " 'analytics',\n",
              " 'company',\n",
              " 'MapR',\n",
              " '.',\n",
              " '“',\n",
              " 'three',\n",
              " 'aspects',\n",
              " '(',\n",
              " 'compute',\n",
              " ',',\n",
              " 'algorithms',\n",
              " ',',\n",
              " 'data',\n",
              " ')',\n",
              " 'make',\n",
              " 'todays',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'possible',\n",
              " '.',\n",
              " 'Also',\n",
              " 'quite',\n",
              " 'frankly',\n",
              " ',',\n",
              " 'lot',\n",
              " 'applications',\n",
              " 'data',\n",
              " 'availability',\n",
              " '...',\n",
              " 'implemented',\n",
              " '25',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'pretty',\n",
              " 'easily',\n",
              " 'data',\n",
              " 'available',\n",
              " 'output',\n",
              " 'model',\n",
              " 'integrated',\n",
              " 'back',\n",
              " 'business',\n",
              " 'flow.',\n",
              " '”',\n",
              " ',',\n",
              " 'many',\n",
              " 'ways',\n",
              " ',',\n",
              " 'Dunning',\n",
              " 'really',\n",
              " 'modern',\n",
              " 'era',\n",
              " 'web',\n",
              " 'key',\n",
              " 'facilitator',\n",
              " 'new',\n",
              " 'age',\n",
              " 'AI',\n",
              " '.',\n",
              " 'Information',\n",
              " 'become',\n",
              " 'ubiquitous',\n",
              " ';',\n",
              " 'also',\n",
              " 'become',\n",
              " 'easier',\n",
              " 'access',\n",
              " 'accurately',\n",
              " 'classified',\n",
              " 'structured',\n",
              " ',',\n",
              " 'semi-structured',\n",
              " 'unstructured',\n",
              " 'data',\n",
              " 'rawest',\n",
              " 'form',\n",
              " '.',\n",
              " 'Tuning',\n",
              " 'AI',\n",
              " 'towards',\n",
              " 'life']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de98aa65-7eb9-4c75-bd8c-a6fb1f4335cd",
      "metadata": {
        "id": "de98aa65-7eb9-4c75-bd8c-a6fb1f4335cd"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbc65ecb-503f-4b95-bbcb-80f6307f50bb",
      "metadata": {
        "tags": [],
        "id": "cbc65ecb-503f-4b95-bbcb-80f6307f50bb",
        "outputId": "0f305397-c566-47bd-d440-5e14b1567f53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(',', 19),\n",
              " ('.', 14),\n",
              " ('AI', 9),\n",
              " ('data', 7),\n",
              " ('(', 4),\n",
              " (')', 4),\n",
              " ('become', 4),\n",
              " ('?', 3),\n",
              " ('lot', 3),\n",
              " ('easier', 3),\n",
              " ('tech', 2),\n",
              " ('world', 2),\n",
              " ('renaissance', 2),\n",
              " ('form', 2),\n",
              " ('platform', 2),\n",
              " ('applications', 2),\n",
              " ('job', 2),\n",
              " ('new', 2),\n",
              " ('analytics', 2),\n",
              " ('right', 2),\n",
              " ('years', 2),\n",
              " ('changes', 2),\n",
              " ('power', 2),\n",
              " ('“', 2),\n",
              " ('compute', 2),\n",
              " ('access', 2),\n",
              " ('”', 2),\n",
              " ('Dunning', 2),\n",
              " ('present-day', 1),\n",
              " ('darling', 1),\n",
              " ('current', 1),\n",
              " ('Artificial', 1),\n",
              " ('Intelligence', 1),\n",
              " ('sister', 1),\n",
              " ('discipline', 1),\n",
              " ('Machine', 1),\n",
              " ('Learning', 1),\n",
              " ('ML', 1),\n",
              " ('led', 1),\n",
              " ('firm', 1),\n",
              " ('worth', 1),\n",
              " ('salt', 1),\n",
              " ('engineer', 1),\n",
              " ('toolsets', 1),\n",
              " ('software', 1),\n",
              " ('IBM', 1),\n",
              " ('CEO', 1),\n",
              " ('Ginni', 1),\n",
              " ('Rometty', 1),\n",
              " ('already', 1),\n",
              " ('proclaimed', 1),\n",
              " ('change', 1),\n",
              " ('100', 1),\n",
              " ('percent', 1),\n",
              " ('jobs', 1),\n",
              " ('next', 1),\n",
              " ('decade', 1),\n",
              " ('mean', 1),\n",
              " ('everybody', 1),\n",
              " (\"'s\", 1),\n",
              " ('mine', 1),\n",
              " ('onward', 1),\n",
              " ('role', 1),\n",
              " ('grain', 1),\n",
              " ('farmers', 1),\n",
              " ('Egypt', 1),\n",
              " ('pastry', 1),\n",
              " ('chefs', 1),\n",
              " ('Paris', 1),\n",
              " ('dog', 1),\n",
              " ('walkers', 1),\n",
              " ('Oregon', 1),\n",
              " ('i.e', 1),\n",
              " ('able', 1),\n",
              " ('help', 1),\n",
              " ('direct', 1),\n",
              " ('workers', 1),\n",
              " ('actions', 1),\n",
              " ('behavior', 1),\n",
              " ('degree', 1),\n",
              " ('intelligence', 1),\n",
              " ('predictive', 1),\n",
              " ('stemming', 1),\n",
              " ('increasingly', 1),\n",
              " ('upon', 1),\n",
              " ('used', 1),\n",
              " ('fanciful', 1),\n",
              " ('notion', 1),\n",
              " ('mostly', 1),\n",
              " ('confined', 1),\n",
              " ('science', 1),\n",
              " ('fiction', 1),\n",
              " ('go', 1),\n",
              " ('recent', 1),\n",
              " ('big', 1),\n",
              " ('technology', 1),\n",
              " ('Aside', 1),\n",
              " ('proliferation', 1),\n",
              " ('mobile', 1),\n",
              " ('devices', 1),\n",
              " ('impacted', 1),\n",
              " ('us', 1),\n",
              " ('memory', 1),\n",
              " ('cheaper', 1),\n",
              " ('storage', 1),\n",
              " ('cloud', 1),\n",
              " ('elsewhere', 1),\n",
              " ('computer', 1),\n",
              " ('processing', 1),\n",
              " ('speeds', 1),\n",
              " ('continued', 1),\n",
              " ('outstrip', 1),\n",
              " ('previous', 1),\n",
              " ('records', 1),\n",
              " ('quantum', 1),\n",
              " ('computing', 1),\n",
              " ('corner', 1),\n",
              " ('simply', 1),\n",
              " ('result', 1),\n",
              " ('coming', 1),\n",
              " ('together', 1),\n",
              " ('‘', 1),\n",
              " ('ingredient', 1),\n",
              " ('’', 1),\n",
              " ('forces', 1),\n",
              " (\"n't\", 1),\n",
              " ('massive', 1),\n",
              " ('important', 1),\n",
              " ('algorithmic', 1),\n",
              " ('developed', 1),\n",
              " ('much', 1),\n",
              " ('gain', 1),\n",
              " ('Internet-connected', 1),\n",
              " ('said', 1),\n",
              " ('Ted', 1),\n",
              " ('CTO', 1),\n",
              " ('company', 1),\n",
              " ('MapR', 1),\n",
              " ('three', 1),\n",
              " ('aspects', 1),\n",
              " ('algorithms', 1),\n",
              " ('make', 1),\n",
              " ('todays', 1),\n",
              " ('machine', 1),\n",
              " ('learning', 1),\n",
              " ('possible', 1),\n",
              " ('Also', 1),\n",
              " ('quite', 1),\n",
              " ('frankly', 1),\n",
              " ('availability', 1),\n",
              " ('...', 1),\n",
              " ('implemented', 1),\n",
              " ('25', 1),\n",
              " ('ago', 1),\n",
              " ('pretty', 1),\n",
              " ('easily', 1),\n",
              " ('available', 1),\n",
              " ('output', 1),\n",
              " ('model', 1),\n",
              " ('integrated', 1),\n",
              " ('back', 1),\n",
              " ('business', 1),\n",
              " ('flow.', 1),\n",
              " ('many', 1),\n",
              " ('ways', 1),\n",
              " ('really', 1),\n",
              " ('modern', 1),\n",
              " ('era', 1),\n",
              " ('web', 1),\n",
              " ('key', 1),\n",
              " ('facilitator', 1),\n",
              " ('age', 1),\n",
              " ('Information', 1),\n",
              " ('ubiquitous', 1),\n",
              " (';', 1),\n",
              " ('also', 1),\n",
              " ('accurately', 1),\n",
              " ('classified', 1),\n",
              " ('structured', 1),\n",
              " ('semi-structured', 1),\n",
              " ('unstructured', 1),\n",
              " ('rawest', 1),\n",
              " ('Tuning', 1),\n",
              " ('towards', 1),\n",
              " ('life', 1)]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(words).most_common()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b7b65a5-21e4-4ff0-947e-f9db27266dad",
      "metadata": {
        "id": "4b7b65a5-21e4-4ff0-947e-f9db27266dad"
      },
      "outputs": [],
      "source": [
        "stemmed_words = []\n",
        "for word in words:\n",
        "    stemmed_words.append(ps.stem(word))\n",
        "    \n",
        "lemmed_words = []\n",
        "for word in stemmed_words:\n",
        "    lemmed_words.append(wn.lemmatize(word))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2ba074-3b5d-466b-8916-394026fd499d",
      "metadata": {
        "id": "0a2ba074-3b5d-466b-8916-394026fd499d",
        "outputId": "d5764ac7-450f-4fce-9157-7f6583a9e153"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(',', 19),\n",
              " ('.', 14),\n",
              " ('ai', 9),\n",
              " ('data', 7),\n",
              " ('(', 4),\n",
              " (')', 4),\n",
              " ('becom', 4),\n",
              " ('comput', 4),\n",
              " ('chang', 3),\n",
              " ('job', 3),\n",
              " ('?', 3),\n",
              " ('lot', 3),\n",
              " ('easier', 3),\n",
              " ('tech', 2),\n",
              " ('world', 2),\n",
              " ('renaiss', 2),\n",
              " ('intellig', 2),\n",
              " ('machin', 2),\n",
              " ('learn', 2),\n",
              " ('form', 2),\n",
              " ('platform', 2),\n",
              " ('applic', 2),\n",
              " ('new', 2),\n",
              " ('analyt', 2),\n",
              " ('right', 2),\n",
              " ('year', 2),\n",
              " ('power', 2),\n",
              " ('“', 2),\n",
              " ('algorithm', 2),\n",
              " ('access', 2),\n",
              " ('”', 2),\n",
              " ('dun', 2),\n",
              " ('also', 2),\n",
              " ('avail', 2),\n",
              " ('present-day', 1),\n",
              " ('darl', 1),\n",
              " ('current', 1),\n",
              " ('artifici', 1),\n",
              " ('sister', 1),\n",
              " ('disciplin', 1),\n",
              " ('ml', 1),\n",
              " ('led', 1),\n",
              " ('firm', 1),\n",
              " ('worth', 1),\n",
              " ('salt', 1),\n",
              " ('engin', 1),\n",
              " ('toolset', 1),\n",
              " ('softwar', 1),\n",
              " ('ibm', 1),\n",
              " ('ceo', 1),\n",
              " ('ginni', 1),\n",
              " ('rometti', 1),\n",
              " ('alreadi', 1),\n",
              " ('proclaim', 1),\n",
              " ('100', 1),\n",
              " ('percent', 1),\n",
              " ('next', 1),\n",
              " ('decad', 1),\n",
              " ('mean', 1),\n",
              " ('everybodi', 1),\n",
              " (\"'s\", 1),\n",
              " ('mine', 1),\n",
              " ('onward', 1),\n",
              " ('role', 1),\n",
              " ('grain', 1),\n",
              " ('farmer', 1),\n",
              " ('egypt', 1),\n",
              " ('pastri', 1),\n",
              " ('chef', 1),\n",
              " ('pari', 1),\n",
              " ('dog', 1),\n",
              " ('walker', 1),\n",
              " ('oregon', 1),\n",
              " ('i.e', 1),\n",
              " ('abl', 1),\n",
              " ('help', 1),\n",
              " ('direct', 1),\n",
              " ('worker', 1),\n",
              " ('action', 1),\n",
              " ('behavior', 1),\n",
              " ('degre', 1),\n",
              " ('predict', 1),\n",
              " ('stem', 1),\n",
              " ('increasingli', 1),\n",
              " ('upon', 1),\n",
              " ('use', 1),\n",
              " ('fanci', 1),\n",
              " ('notion', 1),\n",
              " ('mostli', 1),\n",
              " ('confin', 1),\n",
              " ('scienc', 1),\n",
              " ('fiction', 1),\n",
              " ('go', 1),\n",
              " ('recent', 1),\n",
              " ('big', 1),\n",
              " ('technolog', 1),\n",
              " ('asid', 1),\n",
              " ('prolifer', 1),\n",
              " ('mobil', 1),\n",
              " ('devic', 1),\n",
              " ('impact', 1),\n",
              " ('u', 1),\n",
              " ('memori', 1),\n",
              " ('cheaper', 1),\n",
              " ('storag', 1),\n",
              " ('cloud', 1),\n",
              " ('elsewher', 1),\n",
              " ('process', 1),\n",
              " ('speed', 1),\n",
              " ('continu', 1),\n",
              " ('outstrip', 1),\n",
              " ('previou', 1),\n",
              " ('record', 1),\n",
              " ('quantum', 1),\n",
              " ('corner', 1),\n",
              " ('simpli', 1),\n",
              " ('result', 1),\n",
              " ('come', 1),\n",
              " ('togeth', 1),\n",
              " ('‘', 1),\n",
              " ('ingredi', 1),\n",
              " ('’', 1),\n",
              " ('forc', 1),\n",
              " (\"n't\", 1),\n",
              " ('massiv', 1),\n",
              " ('import', 1),\n",
              " ('develop', 1),\n",
              " ('much', 1),\n",
              " ('gain', 1),\n",
              " ('internet-connect', 1),\n",
              " ('said', 1),\n",
              " ('ted', 1),\n",
              " ('cto', 1),\n",
              " ('compani', 1),\n",
              " ('mapr', 1),\n",
              " ('three', 1),\n",
              " ('aspect', 1),\n",
              " ('make', 1),\n",
              " ('today', 1),\n",
              " ('possibl', 1),\n",
              " ('quit', 1),\n",
              " ('frankli', 1),\n",
              " ('...', 1),\n",
              " ('implement', 1),\n",
              " ('25', 1),\n",
              " ('ago', 1),\n",
              " ('pretti', 1),\n",
              " ('easili', 1),\n",
              " ('output', 1),\n",
              " ('model', 1),\n",
              " ('integr', 1),\n",
              " ('back', 1),\n",
              " ('busi', 1),\n",
              " ('flow.', 1),\n",
              " ('mani', 1),\n",
              " ('way', 1),\n",
              " ('realli', 1),\n",
              " ('modern', 1),\n",
              " ('era', 1),\n",
              " ('web', 1),\n",
              " ('key', 1),\n",
              " ('facilit', 1),\n",
              " ('age', 1),\n",
              " ('inform', 1),\n",
              " ('ubiquit', 1),\n",
              " (';', 1),\n",
              " ('accur', 1),\n",
              " ('classifi', 1),\n",
              " ('structur', 1),\n",
              " ('semi-structur', 1),\n",
              " ('unstructur', 1),\n",
              " ('rawest', 1),\n",
              " ('tune', 1),\n",
              " ('toward', 1),\n",
              " ('life', 1)]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(lemmed_words).most_common()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1637c222-0346-4bfe-8080-7583f91af28b",
      "metadata": {
        "id": "1637c222-0346-4bfe-8080-7583f91af28b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "0121_nlp.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}