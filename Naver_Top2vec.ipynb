{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naver_Top2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOk1zGoq0gYY34IuqJ/2nrd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtype2100/TIL/blob/master/Naver_Top2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK1v6VcmIcJz",
        "outputId": "c765da30-6338-43d0-fb5e-4044f2e91b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c1YJDw2CFlw",
        "outputId": "043ad1d8-713d-4c02-a273-86fc2c105114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting top2vec\n",
            "  Downloading top2vec-1.0.27-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from top2vec) (1.21.6)\n",
            "Collecting hdbscan>=0.8.27\n",
            "  Downloading hdbscan-0.8.28.tar.gz (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 6.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec) (1.5.0)\n",
            "Collecting umap-learn>=0.5.1\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting gensim>=4.0.0\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec) (6.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (1.0.2)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (0.29.28)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->hdbscan>=0.8.27->top2vec) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec) (4.64.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (0.34.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->top2vec) (1.15.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec) (7.1.2)\n",
            "Building wheels for collected packages: hdbscan, umap-learn, pynndescent\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.28-cp37-cp37m-linux_x86_64.whl size=2330810 sha256=763bfdd4b06dd94d3f73b39a2238d0bb14dae59b52b4a87f95f5852cbd0ef198\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/7a/5e/259ccc841c085fc41b99ef4a71e896b62f5161f2bc8a14c97a\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=d09e526a5023bf98ee439ac4cecdb74c26cd02e422c874fb9a81743354d39182\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=118f2d43484a4616e6893365a0ed80fe8f68a6027411632de368b1222e24d650\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n",
            "Successfully built hdbscan umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn, hdbscan, gensim, top2vec\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0 hdbscan-0.8.28 pynndescent-0.5.6 top2vec-1.0.27 umap-learn-0.5.3\n"
          ]
        }
      ],
      "source": [
        "pip install top2vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install top2vec[sentence_encoders]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srxat1Z1CGb9",
        "outputId": "eb79d602-1e5c-4ca4-cc53-33229eb2df02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: top2vec[sentence_encoders] in /usr/local/lib/python3.7/dist-packages (1.0.27)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.5.0)\n",
            "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.8.28)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.21.6)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.5.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.3.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.12.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec[sentence_encoders]) (6.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec[sentence_encoders]) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.0.2)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (0.29.28)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->hdbscan>=0.8.27->top2vec[sentence_encoders]) (3.1.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.5.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (4.64.0)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->top2vec[sentence_encoders]) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.5.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.44.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (14.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.14.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.3.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (4.2.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 66.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.25.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->top2vec[sentence_encoders]) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->top2vec[sentence_encoders]) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.3.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.2.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec[sentence_encoders]) (7.1.2)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install top2vec[sentence_transformers]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2SMFi0YCHHs",
        "outputId": "53eb0b8d-5ef9-484e-8498-9d68f32eda5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: top2vec[sentence_transformers] in /usr/local/lib/python3.7/dist-packages (1.0.27)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_transformers]) (1.3.5)\n",
            "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_transformers]) (0.8.28)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_transformers]) (1.21.6)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_transformers]) (1.5.0)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_transformers]) (0.5.3)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_transformers]) (4.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_transformers]) (1.11.0+cu113)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec[sentence_transformers]) (6.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec[sentence_transformers]) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_transformers]) (1.1.0)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_transformers]) (0.29.28)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_transformers]) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->hdbscan>=0.8.27->top2vec[sentence_transformers]) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_transformers]) (0.51.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_transformers]) (4.64.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_transformers]) (0.5.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_transformers]) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_transformers]) (0.34.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_transformers]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_transformers]) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->top2vec[sentence_transformers]) (1.15.0)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers->top2vec[sentence_transformers]) (0.12.0+cu113)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers->top2vec[sentence_transformers]) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 46.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->top2vec[sentence_transformers]) (4.2.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (7.1.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers->top2vec[sentence_transformers]) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=e3be891b54937540d26db8c993346cf9d3f6c9c382bbfa72553deb99c9ef1409\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=5bb28ad588616a9d08e5b733722e8c7df94618583022dc21a9d1377737059325\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install top2vec[indexing]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p971CnrrCHxU",
        "outputId": "51e86c7e-6228-4b5b-bf8b-9e3a0c8d0a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: top2vec[indexing] in /usr/local/lib/python3.7/dist-packages (1.0.27)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[indexing]) (1.21.6)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from top2vec[indexing]) (0.5.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec[indexing]) (1.3.5)\n",
            "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.7/dist-packages (from top2vec[indexing]) (0.8.28)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[indexing]) (4.2.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec[indexing]) (1.5.0)\n",
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.6.2.tar.gz (31 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec[indexing]) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec[indexing]) (6.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[indexing]) (1.0.2)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[indexing]) (0.29.28)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[indexing]) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->hdbscan>=0.8.27->top2vec[indexing]) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[indexing]) (0.51.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[indexing]) (0.5.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[indexing]) (4.64.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[indexing]) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[indexing]) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[indexing]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[indexing]) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->top2vec[indexing]) (1.15.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec[indexing]) (7.1.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.6.2-cp37-cp37m-linux_x86_64.whl size=1450809 sha256=8f426a42fed2ae5a7894e157818e66b383c0a866bf95f794faddd349b1d5d4f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/01/80/9805daef8cd398ceb20003af220f77c4689cab8e43d466481b\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: hnswlib\n",
            "Successfully installed hnswlib-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xYElvXeXSgYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/Final_project/data_sum/빅카인즈 뉴스/Big_Naver_title_only_증권.xlsx')"
      ],
      "metadata": {
        "id": "hr9729SaSK-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_df = df['제목']"
      ],
      "metadata": {
        "id": "kbKQr5BASK8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lis_df = list(title_df)"
      ],
      "metadata": {
        "id": "xbIuNgj8VgGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Model"
      ],
      "metadata": {
        "id": "lHO73P8PXShH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from top2vec import Top2Vec"
      ],
      "metadata": {
        "id": "sgetfvYsImH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Top2Vec(documents=lis_df, speed=\"learn\", workers=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqWSNbrMCfCk",
        "outputId": "3a6db286-1dae-4557-f94e-eca8b17140f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-06 17:06:40,832 - top2vec - INFO - Pre-processing documents for training\n",
            "2022-05-06 17:06:41,258 - top2vec - INFO - Creating joint document/word embedding\n",
            "2022-05-06 17:06:48,994 - top2vec - INFO - Creating lower dimension embedding of documents\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "2022-05-06 17:07:14,483 - top2vec - INFO - Finding dense areas of documents\n",
            "2022-05-06 17:07:14,637 - top2vec - INFO - Finding topics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get Number of Topics"
      ],
      "metadata": {
        "id": "IMOsP7SMXYRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_num_topics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vBHlTyTChE0",
        "outputId": "014edf63-f3c0-4534-86ec-a10882f7c9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get Topic Sizes"
      ],
      "metadata": {
        "id": "seXUvMPpXaI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_sizes, topic_nums = model.get_topic_sizes()"
      ],
      "metadata": {
        "id": "Tl_0hwe6CjMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get Topics"
      ],
      "metadata": {
        "id": "j34ls_AwXdh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_words"
      ],
      "metadata": {
        "id": "NLPwzR11Y3kM",
        "outputId": "e30d8497-46b3-4c67-cb2c-5ed31118de26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['미래에셋', '실적', '네이버', '플랫폼', '시총', '매출', '상승', '목표주가', '쿠팡', '투자',\n",
              "        '성장', '영업이익', '주가', '특징주', '억원', '조원', '규제', '전년비', '외국인', '신고가',\n",
              "        '급등', '카카오', '강세', '삼성전자', '목표가', '전년比', '사상', '이해진', '하락', '기대',\n",
              "        '클릭', '돌파', '지분', '영업익', '만원', '코스피', '최대', '분기', '주식', '라인',\n",
              "        'e종목', '매수'], dtype='<U4'),\n",
              " array(['규제', '네이버', '주식', '영업익', '라인', '시총', '영업이익', '매출', '성장', '미래에셋',\n",
              "        '실적', '목표주가', '특징주', '억원', '목표가', '최대', '하락', '상승', '플랫폼', '분기',\n",
              "        '강세', '만원', '카카오', '지분', '코스피', '전년비', '돌파', '주가', '급등', 'e종목',\n",
              "        '쿠팡', '사상', '조원', '클릭', '전년比', '기대', '이해진', '투자', '외국인', '신고가',\n",
              "        '삼성전자', '매수'], dtype='<U4'),\n",
              " array(['주식', '외국인', '분기', '투자', '강세', '급등', '클릭', '영업이익', '전년비', '삼성전자',\n",
              "        '시총', '네이버', '코스피', '목표가', '조원', '하락', '이해진', '기대', '특징주', '미래에셋',\n",
              "        '지분', '플랫폼', '실적', '전년比', '카카오', '성장', '매출', '상승', '규제', 'e종목',\n",
              "        '매수', '라인', '억원', '쿠팡', '돌파', '만원', '주가', '영업익', '최대', '목표주가',\n",
              "        '사상', '신고가'], dtype='<U4'),\n",
              " array(['전년比', '전년비', '매출', '분기', '주식', '플랫폼', '최대', '투자', '영업익', '주가',\n",
              "        '네이버', '규제', '특징주', '이해진', '미래에셋', '강세', '급등', '시총', '라인', '카카오',\n",
              "        '만원', '목표주가', '조원', '상승', '삼성전자', '클릭', '성장', '목표가', '억원', '매수',\n",
              "        '외국인', 'e종목', '하락', '기대', '돌파', '지분', '쿠팡', '코스피', '영업이익', '신고가',\n",
              "        '사상', '실적'], dtype='<U4'),\n",
              " array(['시총', '지분', '코스피', '전년比', '투자', '만원', '기대', '이해진', '주가', '상승',\n",
              "        '영업익', '영업이익', '목표주가', '하락', '삼성전자', '분기', '목표가', '네이버', '사상',\n",
              "        '신고가', 'e종목', '쿠팡', '최대', '매출', '성장', '특징주', '플랫폼', '외국인', '실적',\n",
              "        '매수', '전년비', '클릭', '강세', '억원', '카카오', '돌파', '라인', '규제', '조원', '주식',\n",
              "        '미래에셋', '급등'], dtype='<U4')]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_words, word_scores, topic_nums = model.get_topics(10)"
      ],
      "metadata": {
        "id": "1pjs_r2LCkbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Search Topics"
      ],
      "metadata": {
        "id": "7llhVl6nXhjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"네이버\"], num_topics=5)"
      ],
      "metadata": {
        "id": "FO1CLNvsCli7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_nums"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4Bcjqz1CoqM",
        "outputId": "4faf6f5f-fa90-4ef0-efc2-75381572a836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 5, 8, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01JulOxxY0vV",
        "outputId": "cdc3f13b-bf2a-4987-d23b-720d3bf5219d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['미래에셋', '실적', '네이버', '플랫폼', '시총', '매출', '상승', '목표주가', '쿠팡', '투자',\n",
              "        '성장', '영업이익', '주가', '특징주', '억원', '조원', '규제', '전년비', '외국인', '신고가',\n",
              "        '급등', '카카오', '강세', '삼성전자', '목표가', '전년比', '사상', '이해진', '하락', '기대',\n",
              "        '클릭', '돌파', '지분', '영업익', '만원', '코스피', '최대', '분기', '주식', '라인',\n",
              "        'e종목', '매수'], dtype='<U4'),\n",
              " array(['규제', '네이버', '주식', '영업익', '라인', '시총', '영업이익', '매출', '성장', '미래에셋',\n",
              "        '실적', '목표주가', '특징주', '억원', '목표가', '최대', '하락', '상승', '플랫폼', '분기',\n",
              "        '강세', '만원', '카카오', '지분', '코스피', '전년비', '돌파', '주가', '급등', 'e종목',\n",
              "        '쿠팡', '사상', '조원', '클릭', '전년比', '기대', '이해진', '투자', '외국인', '신고가',\n",
              "        '삼성전자', '매수'], dtype='<U4'),\n",
              " array(['주식', '외국인', '분기', '투자', '강세', '급등', '클릭', '영업이익', '전년비', '삼성전자',\n",
              "        '시총', '네이버', '코스피', '목표가', '조원', '하락', '이해진', '기대', '특징주', '미래에셋',\n",
              "        '지분', '플랫폼', '실적', '전년比', '카카오', '성장', '매출', '상승', '규제', 'e종목',\n",
              "        '매수', '라인', '억원', '쿠팡', '돌파', '만원', '주가', '영업익', '최대', '목표주가',\n",
              "        '사상', '신고가'], dtype='<U4'),\n",
              " array(['전년比', '전년비', '매출', '분기', '주식', '플랫폼', '최대', '투자', '영업익', '주가',\n",
              "        '네이버', '규제', '특징주', '이해진', '미래에셋', '강세', '급등', '시총', '라인', '카카오',\n",
              "        '만원', '목표주가', '조원', '상승', '삼성전자', '클릭', '성장', '목표가', '억원', '매수',\n",
              "        '외국인', 'e종목', '하락', '기대', '돌파', '지분', '쿠팡', '코스피', '영업이익', '신고가',\n",
              "        '사상', '실적'], dtype='<U4'),\n",
              " array(['시총', '지분', '코스피', '전년比', '투자', '만원', '기대', '이해진', '주가', '상승',\n",
              "        '영업익', '영업이익', '목표주가', '하락', '삼성전자', '분기', '목표가', '네이버', '사상',\n",
              "        '신고가', 'e종목', '쿠팡', '최대', '매출', '성장', '특징주', '플랫폼', '외국인', '실적',\n",
              "        '매수', '전년비', '클릭', '강세', '억원', '카카오', '돌파', '라인', '규제', '조원', '주식',\n",
              "        '미래에셋', '급등'], dtype='<U4')]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_yIynuRCvGl",
        "outputId": "c0da252e-07e7-4a46-f651-bbb16d0e400e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10788591, 0.09421833, 0.04857818, 0.03029491, 0.01831101])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate Word Clouds"
      ],
      "metadata": {
        "id": "vFSLMh45XkBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"네이버\"], num_topics=5)\n",
        "for topic in topic_nums:\n",
        "    model.generate_topic_wordcloud(topic)"
      ],
      "metadata": {
        "id": "MJYq_OwDCwP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA8raYmhWMCf",
        "outputId": "8a22810f-c3e4-4389-c86d-cec4910ec0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['미래에셋', '실적', '네이버', '플랫폼', '시총', '매출', '상승', '목표주가', '쿠팡', '투자',\n",
              "        '성장', '영업이익', '주가', '특징주', '억원', '조원', '규제', '전년비', '외국인', '신고가',\n",
              "        '급등', '카카오', '강세', '삼성전자', '목표가', '전년比', '사상', '이해진', '하락', '기대',\n",
              "        '클릭', '돌파', '지분', '영업익', '만원', '코스피', '최대', '분기', '주식', '라인',\n",
              "        'e종목', '매수'], dtype='<U4'),\n",
              " array(['규제', '네이버', '주식', '영업익', '라인', '시총', '영업이익', '매출', '성장', '미래에셋',\n",
              "        '실적', '목표주가', '특징주', '억원', '목표가', '최대', '하락', '상승', '플랫폼', '분기',\n",
              "        '강세', '만원', '카카오', '지분', '코스피', '전년비', '돌파', '주가', '급등', 'e종목',\n",
              "        '쿠팡', '사상', '조원', '클릭', '전년比', '기대', '이해진', '투자', '외국인', '신고가',\n",
              "        '삼성전자', '매수'], dtype='<U4'),\n",
              " array(['주식', '외국인', '분기', '투자', '강세', '급등', '클릭', '영업이익', '전년비', '삼성전자',\n",
              "        '시총', '네이버', '코스피', '목표가', '조원', '하락', '이해진', '기대', '특징주', '미래에셋',\n",
              "        '지분', '플랫폼', '실적', '전년比', '카카오', '성장', '매출', '상승', '규제', 'e종목',\n",
              "        '매수', '라인', '억원', '쿠팡', '돌파', '만원', '주가', '영업익', '최대', '목표주가',\n",
              "        '사상', '신고가'], dtype='<U4'),\n",
              " array(['전년比', '전년비', '매출', '분기', '주식', '플랫폼', '최대', '투자', '영업익', '주가',\n",
              "        '네이버', '규제', '특징주', '이해진', '미래에셋', '강세', '급등', '시총', '라인', '카카오',\n",
              "        '만원', '목표주가', '조원', '상승', '삼성전자', '클릭', '성장', '목표가', '억원', '매수',\n",
              "        '외국인', 'e종목', '하락', '기대', '돌파', '지분', '쿠팡', '코스피', '영업이익', '신고가',\n",
              "        '사상', '실적'], dtype='<U4'),\n",
              " array(['시총', '지분', '코스피', '전년比', '투자', '만원', '기대', '이해진', '주가', '상승',\n",
              "        '영업익', '영업이익', '목표주가', '하락', '삼성전자', '분기', '목표가', '네이버', '사상',\n",
              "        '신고가', 'e종목', '쿠팡', '최대', '매출', '성장', '특징주', '플랫폼', '외국인', '실적',\n",
              "        '매수', '전년비', '클릭', '강세', '억원', '카카오', '돌파', '라인', '규제', '조원', '주식',\n",
              "        '미래에셋', '급등'], dtype='<U4')]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Search Documents by Topic"
      ],
      "metadata": {
        "id": "7_UB-6k3XtWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=5, num_docs=10)"
      ],
      "metadata": {
        "id": "9oECGXZRCzys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=5, num_docs=10)\n",
        "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
        "    print(f\"Document: {doc_id}, Score: {score}\")\n",
        "    print(\"-----------\")\n",
        "    print(doc)\n",
        "    print(\"-----------\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9jSq41wC1rU",
        "outputId": "7e464b98-efd0-48e9-a9ff-a2cc3ffd38c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document: 949, Score: 0.3578895032405853\n",
            "-----------\n",
            "네이버, 올해 1Q 매출 15% 늘었지만 라인 등 투자 확대로 영업익은 19.7% 감소\n",
            "-----------\n",
            "\n",
            "Document: 2816, Score: 0.33423930406570435\n",
            "-----------\n",
            "이달 공매도 1위 LG화학 삼성전자 카뱅 네이버 뒤이어\n",
            "-----------\n",
            "\n",
            "Document: 894, Score: 0.3299049139022827\n",
            "-----------\n",
            "[컨콜] 네이버 \"동영상 오디오 콘텐츠 확보, 생태계 마련 노력할 것\"\n",
            "-----------\n",
            "\n",
            "Document: 2374, Score: 0.3160068690776825\n",
            "-----------\n",
            "\"2분기 Z홀딩스 두자릿수 성장, 네이버 900억원 지분법 기여\"-현대차\n",
            "-----------\n",
            "\n",
            "Document: 2615, Score: 0.3159743547439575\n",
            "-----------\n",
            "네이버, 日 전자책 시장 공략 박차・・・1716억원 신규 투자\n",
            "-----------\n",
            "\n",
            "Document: 1743, Score: 0.31073662638664246\n",
            "-----------\n",
            "\"계속 간다\" 카카오 신고가..네이버도 강세\n",
            "-----------\n",
            "\n",
            "Document: 911, Score: 0.308401495218277\n",
            "-----------\n",
            "\"1조 클럽 무너진 네이버, 기다림이 필요해\"\n",
            "-----------\n",
            "\n",
            "Document: 2232, Score: 0.2891724407672882\n",
            "-----------\n",
            "코스피, 개인 매수세에 3270선 상승 출발 카카오 네이버 강세\n",
            "-----------\n",
            "\n",
            "Document: 1594, Score: 0.28189894556999207\n",
            "-----------\n",
            "[시그널]빅히트 기업가치 JYP 3배 “네이버 카카오와 경쟁”\n",
            "-----------\n",
            "\n",
            "Document: 845, Score: 0.2663276493549347\n",
            "-----------\n",
            "네이버 전직원 年1000만원씩 스톡옵션\n",
            "-----------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Semantic Search Documents by Keywords"
      ],
      "metadata": {
        "id": "vKdgIztsX2s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents, document_scores, document_ids = model.search_documents_by_keywords(keywords=[\"네이버\"], num_docs=10)\n",
        "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
        "    print(f\"Document: {doc_id}, Score: {score}\")\n",
        "    print(\"-----------\")\n",
        "    print(doc)\n",
        "    print(\"-----------\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9785NvhC26E",
        "outputId": "65a56e83-bd84-4cf6-e191-74631c827688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document: 3, Score: 0.2052726447582245\n",
            "-----------\n",
            "'벤처 큰손'으로 뜨는 네이버 7000억 투자 '시동'\n",
            "-----------\n",
            "\n",
            "Document: 2406, Score: 0.19373196363449097\n",
            "-----------\n",
            "코스피, 외인 매도세에 낙폭 키워 네이버 카카오 3% 가까이 내림세\n",
            "-----------\n",
            "\n",
            "Document: 788, Score: 0.17180460691452026\n",
            "-----------\n",
            "네이버, 올해 3Q 매출 1조3977억원 전년 동기比 16.4%↑ (2보)\n",
            "-----------\n",
            "\n",
            "Document: 573, Score: 0.17101068794727325\n",
            "-----------\n",
            "네이버 카카오 20% 추락 국내 기술주도 부진\n",
            "-----------\n",
            "\n",
            "Document: 1601, Score: 0.1684618443250656\n",
            "-----------\n",
            "코스피 코스닥 상승 전환 네이버 4% 가까이 하락\n",
            "-----------\n",
            "\n",
            "Document: 434, Score: 0.16342860460281372\n",
            "-----------\n",
            "양대 포털의 차별화된 M&A 공식 네이버 '기관총식 투자' vs 카카오 '대포식 투자'\n",
            "-----------\n",
            "\n",
            "Document: 1631, Score: 0.16193650662899017\n",
            "-----------\n",
            "[특징주] 네이버가 일부 지분 인수한다는데...CJ대한통운 장 초반 약세\n",
            "-----------\n",
            "\n",
            "Document: 379, Score: 0.1606566309928894\n",
            "-----------\n",
            "[ET투자뉴스]NAVER, \"향후 네이버의 실적 \" 매수-하나금융투자\n",
            "-----------\n",
            "\n",
            "Document: 1611, Score: 0.15897636115550995\n",
            "-----------\n",
            "네이버 카카오 추석전 털고갈까 전문가들은 \"아직 팔때아냐\"\n",
            "-----------\n",
            "\n",
            "Document: 1878, Score: 0.15856869518756866\n",
            "-----------\n",
            "‘외국인 픽’ 네이버 카카오 연일 최고가\n",
            "-----------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Similar Keywords"
      ],
      "metadata": {
        "id": "G9VRIOjrX6LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words, word_scores = model.similar_words(keywords=[\"네이버\"], keywords_neg=[], num_words=20)\n",
        "for word, score in zip(words, word_scores):\n",
        "    print(f\"{word} {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-poOhLHCC4bU",
        "outputId": "d5cba490-dcc3-44f8-e377-671dc534f82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "강세 0.1973171608838695\n",
            "전년比 0.1080710668333141\n",
            "조원 0.09176265291106878\n",
            "목표가 0.08786463422283154\n",
            "코스피 0.0871721404892761\n",
            "시총 0.08133658052561582\n",
            "하락 0.06967791650744908\n",
            "급등 0.06540300918536036\n",
            "기대 0.06092206374693751\n",
            "목표주가 0.05285873028356545\n",
            "투자 0.05250178896298115\n",
            "규제 0.04035983452035097\n",
            "분기 0.0373217285610869\n",
            "전년비 0.03524097210670676\n",
            "영업익 0.027562636863047073\n",
            "주식 0.02379682971920781\n",
            "실적 0.016683192919384672\n",
            "상승 0.01428315375839484\n",
            "특징주 0.01268605553327764\n",
            "미래에셋 0.011010446851457533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "soCIzxhnC5z8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}